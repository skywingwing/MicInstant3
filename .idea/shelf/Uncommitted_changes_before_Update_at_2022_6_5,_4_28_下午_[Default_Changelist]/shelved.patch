Index: app/src/main/java/org/pytorch/demo/speechrecognition/MainActivity.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>package org.pytorch.demo.speechrecognition;\n\nimport android.Manifest;\nimport android.accessibilityservice.AccessibilityService;\nimport android.animation.ValueAnimator;\nimport android.annotation.SuppressLint;\nimport android.app.Activity;\nimport android.content.Context;\nimport android.content.Intent;\nimport android.content.pm.PackageInfo;\nimport android.content.pm.PackageManager;\nimport android.graphics.PixelFormat;\nimport android.graphics.drawable.Drawable;\nimport android.hardware.Sensor;\nimport android.hardware.SensorEvent;\nimport android.hardware.SensorEventListener;\nimport android.hardware.SensorManager;\nimport android.media.AudioFormat;\nimport android.media.AudioManager;\nimport android.media.AudioRecord;\nimport android.media.MediaRecorder;\nimport android.media.MediaScannerConnection;\nimport android.media.SoundPool;\nimport android.net.Uri;\nimport android.os.Build;\nimport android.os.Bundle;\nimport android.os.Environment;\nimport android.os.Handler;\nimport android.os.HandlerThread;\nimport android.os.Looper;\nimport android.os.ParcelFileDescriptor;\nimport android.os.VibrationEffect;\nimport android.os.Vibrator;\nimport android.provider.Settings;\nimport android.speech.RecognitionListener;\nimport android.speech.RecognizerIntent;\nimport android.speech.SpeechRecognizer;\nimport android.text.TextUtils;\nimport android.util.Log;\nimport android.view.Gravity;\nimport android.view.LayoutInflater;\nimport android.view.View;\nimport android.view.WindowManager;\nimport android.view.accessibility.AccessibilityEvent;\nimport android.view.accessibility.AccessibilityNodeInfo;\nimport android.widget.Button;\nimport android.widget.FrameLayout;\nimport android.widget.ImageButton;\nimport android.widget.ImageView;\nimport android.widget.ProgressBar;\nimport android.widget.TextView;\nimport android.widget.Toast;\n\nimport androidx.appcompat.app.AppCompatActivity;\nimport androidx.core.app.ActivityCompat;\nimport androidx.core.content.ContextCompat;\n\n\nimport org.pytorch.IValue;\nimport org.pytorch.Module;\nimport org.pytorch.Tensor;\n\nimport java.io.BufferedWriter;\nimport java.io.File;\nimport java.io.FileInputStream;\nimport java.io.FileNotFoundException;\nimport java.io.FileOutputStream;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.OutputStream;\nimport java.io.OutputStreamWriter;\nimport java.nio.FloatBuffer;\nimport java.nio.MappedByteBuffer;\nimport java.text.BreakIterator;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Locale;\nimport java.util.Timer;\nimport java.util.TimerTask;\n\n\nimport org.pytorch.LiteModuleLoader;\n\nimport com.chaquo.python.Python;\n//import com.chaquo.python.android.AndroidPlatform;\nimport com.chaquo.python.PyObject;\n//import com.chaquo.python.Kwarg;\n\nimport org.tensorflow.lite.Interpreter;\nimport org.tensorflow.lite.support.common.FileUtil;\n\n\n\n\npublic class MainActivity extends AppCompatActivity implements Runnable {\n    private static final String TAG = MainActivity.class.getName();\n\n    private Module mModuleEncoder;\n    private TextView mtvEmoState;\n    public TextView mtvTest;\n    private ImageButton mButton;\n    private ImageButton mImgbExtractFeature;\n    private ImageButton mImgbCheckFeature;\n    private ImageView mImgvEmoState;\n    private ProgressBar mprobarEmoInference;\n    private boolean mButtonisPlay=false;\n\n\n    private int EmoState=EMO_NEUTRAL;\n    private float EmoInference=0;\n\n    private final static int EMO_NEUTRAL=1;\n    private final static int EMO_ANGER=2;\n    private final static int REQUEST_RECORD_AUDIO = 13;\n    private final static int AUDIO_LEN_IN_SECOND = 5;\n    private final static int SAMPLE_RATE = 16000;//22050;//16000;\n    private final static int RECORDING_LENGTH = SAMPLE_RATE * AUDIO_LEN_IN_SECOND;\n\n    private final static int ChangeMicState_Drop_InRequest=-1;\n    private final static int ChangeMicState_Changed=1;\n\n    private final static int HOP_LENGTH=512;\n    private final static int FRAME_LENGTH=2048;\n\n    private final static String LOG_TAG = MainActivity.class.getSimpleName();\n\n    private int mStart = 1;\n    private HandlerThread mTimerThread;\n    private Handler mTimerHandler;\n\n\n    public final static int MIC_ON=1;\n    public final static int MIC_OFF=2;\n\n    public final static int MIC_INREQUEST=1;\n    public final static int MIC_NOREQUEST=2;\n\n    private final static int Announce_Mode=0;//最终模式，同时包括倒置开麦和拍拍开麦\n    private final static int GreatMeeting_Mode=1;//倒置麦克风开麦\n    private final static int HandFree_mode=2;//拍拍开麦\n\n    private SensorManager sm;\n    private Sensor mSensorOrientation;\n    private SensListener sensListener=new SensListener();\n\n    private Vibrator vibrator;\n    private SensorManager sensorManager;\n    private SpeechRecognizer speechRecognizer;\n    private int samplingPeriod = 10000;\n\n    private static int seqLength = 60;\n    private float[][][] input = new float[1][seqLength][6];\n\n    private long[] lastTime = new long[2];\n    private long firstTapTime = 0;\n    private int skipNum = seqLength;\n    private boolean secondFlag = false;\n\n    private MappedByteBuffer firstModel;\n    private MappedByteBuffer secondModel;\n    private Interpreter firstInterpreter;\n    private Interpreter secondInterpreter;\n    private final Interpreter.Options tfliteOptions = new Interpreter.Options();\n    private float[][] output = new float[1][3];\n\n    private List<Long> lastRecognizedTime = new ArrayList<>();\n\n    private int MicInstantMode=Announce_Mode;\n    public static int MicStateRequest=MIC_NOREQUEST;\n    public static int MicState=MIC_OFF;\n    private static boolean MicReveseOn=false;//仅在倒置开麦的情况下触发正置关麦\n\n    private TextView mtvMicInstantMode;\n\n    private SoundPool soundPool;\n\n    Intent speechRecognizerIntent;\n    private HandlerThread TimerThread;\n    private Handler TimerHandler;\n    private int Timer_time=0;\n\n    Thread SensorService_thread;\n    Thread FloatingWindow_thread;\n    Thread SpeechDetector_thread;\n    Thread VoicePrint_thread;\n    //Thread MicOnTimer_thread;\n\n    private HandlerThread MicOnTimerThread;\n    private Handler MicOnTimerHandler;\n    private int MicOnTimer_time=0;\n    private int MicOnTimerState=MicOnTimerState_INACTIVE;\n    private final static int MicOnTimerState_INACTIVE=1;\n    private final static int MicOnTimerState_ACTIVE=2;\n\n    //AudioManager audiomanage = (AudioManager)getApplicationContext().getSystemService(Context.AUDIO_SERVICE);\n\n    Handler FloatingWindow_handler=new Handler(Looper.getMainLooper());\n\n    private int VoicePrintFlag=0;\n    private static int VoicePrint_CREATEFEATURE=0;\n    private static int VoicePrint_CHECKFEATURE=1;\n    private static int VoicePrint_CHECKGROUP=2;\n\n    private VoicePrint voicePrint=new VoicePrint();\n\n\n\n    //private TMAccessibilityService TMcontrol=new TMAccessibilityService();\n\n\n\n    private Runnable mRunnable = new Runnable() {\n        @Override\n        public void run() {\n            mTimerHandler.postDelayed(mRunnable, 1000);\n            Log.i(TAG,\"recorder timer\");\n\n            MainActivity.this.runOnUiThread(\n                    () -> {\n                        mtvTest.setText(String.format(\"Listening - %ds left\", AUDIO_LEN_IN_SECOND - mStart));\n                        mStart += 1;\n                    });\n        }\n    };\n\n\n    private Runnable SensorService_runnable =new Runnable() {\n        @Override\n        public void run() {\n            initSensor();\n        }\n    };\n\n\n    Runnable FloatingWindow_runnable =new Runnable() {\n        @Override\n        public void run(){\n            //TmAccessibilityService.initFloatingWindow();\n            try {\n                startService(new Intent(MainActivity.this, FloatWindow.class));\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n        }\n    };\n\n\n    Runnable MicOnTimer_runnable=new Runnable() {\n        @Override\n        public void run() {\n            MicOnTimerHandler.postDelayed(MicOnTimer_runnable, 1000);\n            if(MicState==MIC_ON&&!MicReveseOn&&MicOnTimerState==MicOnTimerState_INACTIVE) {\n                MicOnTimerState=MicOnTimerState_ACTIVE;\n            }\n            if (MicOnTimerState == MicOnTimerState_ACTIVE) {\n                MicOnTimer_time += 1;\n                Log.i(TAG, \"MicOnTimer running:\" + MicOnTimer_time);\n                if (MicOnTimer_time > 5) {\n                    MicOnTimer_time = 0;\n                    if (!MicReveseOn) {\n                        changeMicState(MIC_OFF);\n                    }\n                    //stopMicOnTimer();\n                    Log.i(TAG, \"MicOnTimer triggered:\" + MicOnTimer_time);\n                    //speechRecognizer.stopListening();\n                }\n            }\n        }\n    };\n    public void ChaneMicOnTimerState(int MicOnTimerState) {\n        MicOnTimer_time = 0;\n        this.MicOnTimerState=MicOnTimerState;\n\n    }\n    protected void stopMicOnTimer() {\n        if (MicOnTimerThread!=null) {\n            MicOnTimerThread.quitSafely();\n            try {\n                MicOnTimerThread.join();\n                MicOnTimerThread = null;\n                MicOnTimerHandler = null;\n                MicOnTimer_time = 0;\n                Log.e(TAG, \"MicOnTimer stop\");\n            } catch (InterruptedException e) {\n                Log.e(TAG, \"Error on stopping background thread\", e);\n            }\n        }\n    }\n\n\n    protected boolean CheckMicOnTimerRunning(){\n        if(MicOnTimerThread!=null){\n            return true;\n        }\n        else {\n            return false;\n        }\n    }\n    private void startMicOnTimer(){\n        //Thread thread = new Thread(MainActivity.this);\n        //thread.start();\n        MicOnTimerThread = new HandlerThread(\"ClockTimer\");\n        MicOnTimerThread.start();\n        MicOnTimerHandler = new Handler(MicOnTimerThread.getLooper());\n        MicOnTimerHandler.postDelayed(MicOnTimer_runnable, 1000);\n        Log.e(TAG, \"startMicOnTimer\");\n    }\n\n\n    protected void stopTimerThread() {\n        mTimerThread.quitSafely();\n        try {\n            mTimerThread.join();\n            mTimerThread = null;\n            mTimerHandler = null;\n            mStart = 1;\n        } catch (InterruptedException e) {\n            Log.e(TAG, \"Error on stopping background thread\", e);\n        }\n    }\n\n\n    @SuppressLint(\"WrongViewCast\")\n    @Override\n    protected void onCreate(Bundle savedInstanceState) {\n        super.onCreate(savedInstanceState);\n        setContentView(R.layout.activity_main);\n        getSupportActionBar().hide();\n        mButton = findViewById(R.id.imgbtnSorP);\n        mButton.setImageResource(R.drawable.icon2);\n        mImgvEmoState=findViewById(R.id.imgvEmoState);\n        mImgbExtractFeature=findViewById(R.id.imgbtnExtractFeature);\n        mImgbCheckFeature=findViewById(R.id.imgbtnCheckFeature);\n        mtvEmoState = findViewById(R.id.tvState);\n        mtvTest=findViewById(R.id.tvTest);\n        mprobarEmoInference=findViewById(R.id.probarEmoInference);\n\n        mtvMicInstantMode = findViewById(R.id.tvMicInstantMode);\n        mprobarEmoInference.setProgress(1);\n\n        //initVoicePrint();\n        startMicOnTimer();\n\n        mButton.setOnClickListener(new View.OnClickListener() {\n            public void onClick(View v) {\n//                //mButton.setText(String.format(\"Listening - %ds left\", AUDIO_LEN_IN_SECOND));\n//                mButton.setEnabled(false);\n//\n//                Thread thread = new Thread(MainActivity.this);\n//                thread.start();\n//\n//                mTimerThread = new HandlerThread(\"Timer\");\n//                mTimerThread.start();\n//                mTimerHandler = new Handler(mTimerThread.getLooper());\n//                mTimerHandler.postDelayed(mRunnable, 1000);\n//                if(mButtonisPlay){\n//                    ((ImageButton)v).setImageResource(R.drawable.icon2);\n//                    mtvTest.setText(\"Stop Run\");\n//                }\n//                else{\n//                    ((ImageButton)v).setImageResource(R.drawable.icon1);\n//                    mtvTest.setText(\"Recording\");\n//                }\n//                mButtonisPlay = !mButtonisPlay;\n                if (MicInstantMode==Announce_Mode){\n                    MicInstantMode=GreatMeeting_Mode;\n                    mtvMicInstantMode.setText(\"       GreatMeeting\");\n                }\n                else if(MicInstantMode==GreatMeeting_Mode){\n                    MicInstantMode=HandFree_mode;\n                    mtvMicInstantMode.setText(\"       HandFree\");\n                }\n                else if(MicInstantMode==HandFree_mode){\n                    MicInstantMode=Announce_Mode;\n                    mtvMicInstantMode.setText(\"   AnnounceMode\");\n                }\n                mButtonisPlay = !mButtonisPlay;\n            }\n        });\n//        mImgbExtractFeature.setOnClickListener(new View.OnClickListener() {\n//            public void onClick(View v) {\n//                startVoicePrint(VoicePrint_CREATEFEATURE);\n//                mButtonisPlay = !mButtonisPlay;\n//\n//            }\n//        });\n//        mImgbCheckFeature.setOnClickListener(new View.OnClickListener() {\n//            public void onClick(View v) {\n//                startVoicePrint(VoicePrint_CHECKFEATURE);\n//                mButtonisPlay = !mButtonisPlay;\n//            }\n//        });\n        //requestMicrophonePermission();\n\n        //initSensor();\n        //initSpeechDetector();\n        Log.i(TAG, \"Main::oncreate done \");\n\n        Utils.writeTxtToFile(Utils.GetSystemTime()+\" \"+\"Main::oncreate done \",\"/logs\",\"/log.txt\");\n        //startTimer();\n\n        //initAccessibility(this.getApplicationContext(),\"TMAccessibilityService\");\n    }\n\n    @Override\n    protected void onResume() {\n        super.onResume();\n        Utils.writeTxtToFile(\"onResume \",\"/logs\",\"log.txt\");\n        if (!TmAccessibilityService.isStart()) {\n            try {\n                this.startActivity(new Intent(Settings.ACTION_ACCESSIBILITY_SETTINGS));\n            } catch (Exception e) {\n                this.startActivity(new Intent(Settings.ACTION_SETTINGS));\n                e.printStackTrace();\n            }\n        }\n        else {\n            InitafterTmConnected();\n        }\n    }\n    public void InitafterTmConnected(){\n        if(SensorService_thread==null) {\n            requestStoragePermission();\n            initSoudpool();\n            SensorService_thread = new Thread(SensorService_runnable);\n            SensorService_thread.start();\n        }\n        if(FloatingWindow_thread==null){\n            if(Settings.canDrawOverlays(this)){\n                Log.i(TAG,\"start floating window...\");\n                FloatingWindow_thread=new Thread(FloatingWindow_runnable);\n                FloatingWindow_thread.start();\n                //SpeechDetector_thread=new Thread(SpeechDetector_runnable);\n                //SpeechDetector_thread.start();\n                //initSpeechDetector();\n                //SpeechDetect();\n                //System.out.println(FloatWindow.isStart());\n                startApp(\"com.tencent.wemeet.app\");\n                Utils.writeTxtToFile(\"com.tencent.wemeet.app1\",\"/logs\",\"log.txt\");\n\n\n//                    TmAccessibilityService.mService.startFloatingWindow();\n            }\n            else {\n                requestFloatingWindow();\n            }\n        }\n    }\n\n    @SuppressLint(\"WrongConstant\")\n    private void startApp(String packname){\n        PackageManager packageManager = getPackageManager();\n        if (checkPackInfo(packname)) {\n            Intent intent = packageManager.getLaunchIntentForPackage(packname);\n            startActivity(intent);\n        } else {\n            Toast.makeText(MainActivity.this, \"没有安装\" + packname, 1).show();\n        }\n    }\n    private boolean checkPackInfo(String packname) {\n        PackageInfo packageInfo = null;\n        try {\n            packageInfo = getPackageManager().getPackageInfo(packname, 0);\n        } catch (PackageManager.NameNotFoundException e) {\n            e.printStackTrace();\n        }\n        return packageInfo != null;\n    }\n\n\n    private void requestFloatingWindow(){\n        Toast.makeText(this, \"Please permit float window...\", Toast.LENGTH_SHORT);\n        Intent intent = new Intent();\n        intent.setAction(Settings.ACTION_MANAGE_OVERLAY_PERMISSION);\n        intent.setData(Uri.parse(\"package:\" + getPackageName()));\n        startActivityForResult(intent, 0);\n    }\n\n\n    private void initSoudpool(){\n        soundPool= new SoundPool.Builder()\n                .setMaxStreams(10)\n                .build();\n        soundPool.load(this,R.raw.sound_micon,1);\n        soundPool.load(this,R.raw.sound_micoff,2);\n    }\n\n    public void initSensor(){\n        //倒置控制\n        sm = (SensorManager) getSystemService(SENSOR_SERVICE);\n        // 获取方向传感器\n        mSensorOrientation = sm.getDefaultSensor(Sensor.TYPE_MAGNETIC_FIELD);\n        //注册数值变化监听器\n        sm.registerListener(sensListener, mSensorOrientation,SensorManager.SENSOR_DELAY_UI);\n\n        //PatPat控制\n        vibrator = (Vibrator)getSystemService(Context.VIBRATOR_SERVICE);\n        sensorManager = (SensorManager) getSystemService(Context.SENSOR_SERVICE);\n        Sensor gyroSensor = sensorManager.getDefaultSensor(Sensor.TYPE_GYROSCOPE);\n        sensorManager.registerListener(gyroListener, gyroSensor, samplingPeriod);\n        Sensor linearAccSensor = sensorManager.getDefaultSensor(Sensor.TYPE_LINEAR_ACCELERATION);\n        sensorManager.registerListener(linearAccListener, linearAccSensor, samplingPeriod);\n\n        tfliteOptions.setNumThreads(4);\n        try {\n            firstModel = FileUtil.loadMappedFile(getApplicationContext(), String.format(\"first.tflite\"));\n            //firstModel = FileUtil.loadMappedFile(assetFilePath(getApplicationContext(), \"Model2.ptl\"));\n            firstInterpreter = new Interpreter(firstModel, tfliteOptions);\n        } catch (IOException e) {\n            Log.e(\"Load Model\", \"model load fail\");\n            e.printStackTrace();\n            System.out.println(\"first model load fail\");\n        }\n        try {\n            secondModel = FileUtil.loadMappedFile(getApplicationContext(), String.format(\"second.tflite\"));\n            secondInterpreter = new Interpreter(secondModel, tfliteOptions);\n        } catch (IOException e) {\n            Log.e(\"Load Model\", \"model load fail\");\n            e.printStackTrace();\n            System.out.println(\"second model load fail\");\n        }\n    }\n\n    private class SensListener extends AppCompatActivity implements SensorEventListener {\n        private float Mx,My,Mz;\n\n        // 传感器数值变化会调用此方法\n\n        @Override\n        public void onSensorChanged( SensorEvent event) {\n            Mx=(float) (Math.round(event.values[0] * 100)) / 100;\n            My=(float) (Math.round(event.values[1] * 100)) / 100;//手机纵向地磁加速度\n            Mz=(float) (Math.round(event.values[2] * 100)) / 100;\n\n            runOnUiThread(new Runnable() {\n                @Override\n                public void run() {\n                    mtvTest.setText(String.valueOf(Mx)+\"\\n\"+String.valueOf(My)+\"\\n\"+String.valueOf(Mz));\n                }\n\n            });\n            if(MicInstantMode==GreatMeeting_Mode || MicInstantMode==Announce_Mode){\n                CheckGesture();\n            }\n\n        }\n\n        private void CheckGesture(){\n            if (My>40 && Math.abs(My)>(Math.abs(Mx+Mz)*2)){\n                if(!MicReveseOn) {\n                    MicReveseOn=true;\n                    changeMicState(MIC_ON);\n                    Utils.writeTxtToFile(Utils.GetSystemTime()+\" \"+\"Main::oncreate done \",\"/logs\",\"/log.txt\");\n                    Log.i(TAG, \"CheckGesture:Phone reverted\");\n                }\n                if (CheckMicOnTimerRunning()) {\n                    ChaneMicOnTimerState(MicOnTimerState_INACTIVE);\n                }\n                MicReveseOn=true;\n\n            }\n            else if(My<-40 && Math.abs(My)>(Math.abs(Mx+Mz)*2) ){\n                if(MicState==MIC_ON &&MicReveseOn) {\n                    changeMicState(MIC_OFF);\n                    Log.i(TAG, \"CheckGesture:Phone returned\");\n                }\n                MicReveseOn=false;\n\n            }\n\n        }\n\n        @Override\n        public void onAccuracyChanged(Sensor sensor, int accuracy) {\n        }\n\n    }\n\n    private int changeMicState(int Micstate){\n        if (MicStateRequest==MIC_NOREQUEST) {\n            MicStateRequest=MIC_INREQUEST;\n            int res;\n            String MicHint = \"\";\n            //startTimer();\n            if (Micstate == MicState) {\n                Log.i(TAG,\"changeMicState: request already done, drop this request...now Mic state:\"+String.valueOf(MicState));\n\n            } else {\n                if (Micstate == MIC_ON) {\n\n                    res = R.drawable.mic_on;\n                    if (TmAccessibilityService.mService.CheckMicOn() == 0) {\n                        TmAccessibilityService.mService.ClickView(TmAccessibilityService.mService.vid_InMeeting_Mic);\n                    }\n                    TmAccessibilityService.mService.SetMicMute(false);\n                    ChaneMicOnTimerState(MicOnTimerState_ACTIVE);\n\n                    MicState = MIC_ON;\n                    soundPool.play(1, 1, 1, 0, 0, 1);\n\n                    MicHint = \"Microphone ON!\";\n\n\n                } else if (Micstate == MIC_OFF) {\n\n                    res = R.drawable.mic_off;\n                    if (TmAccessibilityService.mService.CheckMicOn() == 1) {\n                        TmAccessibilityService.mService.ClickView(TmAccessibilityService.mService.vid_InMeeting_Mic);\n                        //audiomanage.setMicrophoneMute(true);\n                    }\n                    ChaneMicOnTimerState(MicOnTimerState_INACTIVE);\n                    MicState = MIC_OFF;\n                    MicReveseOn=false;\n                    soundPool.play(2, 1, 1, 0, 0, 1);\n                    MicHint = \"Microphone OFF!\";\n                } else {\n                    MicState = MIC_OFF;\n                    res = R.drawable.mic_off;\n                    if (TmAccessibilityService.mService.CheckMicOn() == 1) {\n                        TmAccessibilityService.mService.ClickView(TmAccessibilityService.mService.vid_InMeeting_Mic);\n                    }\n                    TmAccessibilityService.mService.SetMicMute(true);\n\n                    ChaneMicOnTimerState(MicOnTimerState_INACTIVE);\n\n                    MicReveseOn=false;\n                    MicHint = \"Microphone OFF!\";\n                }\n                mImgvEmoState.setImageResource(res);\n                mtvEmoState.setText(MicHint);\n            }\n            MicStateRequest=MIC_NOREQUEST;\n            return ChangeMicState_Changed;\n        }\n        else {\n            Log.i(TAG,\"changeMicState: MicStateRequest==MIC_INREQUEST, drop this request...\");\n            return ChangeMicState_Drop_InRequest;\n        }\n\n    }\n\n    private Runnable SpeechDetector_runnable =new Runnable() {\n        @Override\n        public void run() {\n            initSpeechDetector();\n        }\n    };\n\n    private void initSpeechDetector(){\n        speechRecognizer = SpeechRecognizer.createSpeechRecognizer(this);\n\n        speechRecognizerIntent = new Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH);\n        speechRecognizerIntent.putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL,RecognizerIntent.LANGUAGE_MODEL_FREE_FORM);\n        speechRecognizerIntent.putExtra(RecognizerIntent.EXTRA_LANGUAGE, Locale.getDefault());\n        speechRecognizer.setRecognitionListener(new RecognitionListener() {\n            @Override\n            public void onReadyForSpeech(Bundle bundle) {\n            }\n            @Override\n            public void onBeginningOfSpeech() {\n                System.out.println(\"start detecting...\");\n            }\n            @Override\n            public void onRmsChanged(float v) {\n            }\n            @Override\n            public void onBufferReceived(byte[] bytes) {\n            }\n\n            @Override\n            public void onEndOfSpeech() {\n            }\n            @Override\n            public void onError(int i) {\n            }\n\n            @Override\n            public void onResults(Bundle bundle) {\n                ArrayList<String> data = bundle.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION);\n                if (data.size()<1){\n                    Log.i(TAG,\"no speech detected!\");\n                }\n                else {\n                    for (int i = 0; i < data.size(); i++) {\n                        System.out.println(data.get(i));\n                    }\n                }\n            }\n\n            @Override\n            public void onPartialResults(Bundle bundle) {\n            }\n\n            @Override\n            public void onEvent(int i, Bundle bundle) {\n            }\n        });\n    }\n    private void SpeechDetect(){\n\n        speechRecognizer.startListening(speechRecognizerIntent);\n        startTimer();\n\n    }\n\n    private Runnable TimerRunnable = new Runnable() {\n        @Override\n        public void run() {\n            TimerHandler.postDelayed(TimerRunnable, 1000);\n            Timer_time+=1;\n            Log.e(TAG, \"Timer running\");\n            if(Timer_time>5){\n                stopTimer();\n                Log.i(TAG,\"Timer:\"+Timer_time);\n                //speechRecognizer.stopListening();\n            }\n        }\n    };\n    protected void stopTimer() {\n        TimerThread.quitSafely();\n        try {\n            TimerThread.join();\n            TimerThread = null;\n            TimerHandler = null;\n            speechRecognizer.stopListening();\n            Timer_time = 0;\n        } catch (InterruptedException e) {\n            Log.e(TAG, \"Error on stopping background thread\", e);\n        }\n    }\n    private void startTimer(){\n        //Thread thread = new Thread(MainActivity.this);\n        //thread.start();\n\n        TimerThread = new HandlerThread(\"ClockTimer\");\n        TimerThread.start();\n        TimerHandler = new Handler(TimerThread.getLooper());\n        TimerHandler.postDelayed(TimerRunnable, 1000);\n        Log.e(TAG, \"startTimer\");\n    }\n\n    private void initAccessibility(Context ct, String serviceClass){\n        boolean haspermisssion=false;\n        int ok = 0;\n        try {\n            ok = Settings.Secure.getInt(ct.getContentResolver(), Settings.Secure.ACCESSIBILITY_ENABLED);\n        } catch (Settings.SettingNotFoundException e) {\n        }\n\n        TextUtils.SimpleStringSplitter ms = new TextUtils.SimpleStringSplitter(':');\n        if (ok == 1) {\n            String settingValue = Settings.Secure.getString(ct.getContentResolver(), Settings.Secure.ENABLED_ACCESSIBILITY_SERVICES);\n            if (settingValue != null) {\n                ms.setString(settingValue);\n                while (ms.hasNext()) {\n                    String accessibilityService = ms.next();\n                    if (accessibilityService.contains(serviceClass)) {\n                        haspermisssion=true;\n                    }\n                }\n            }\n        }\n\n        if (!haspermisssion){\n            // jump to setting permission\n            Intent intent = new Intent(Settings.ACTION_ACCESSIBILITY_SETTINGS);\n            intent.addFlags(Intent.FLAG_ACTIVITY_NEW_TASK);\n            ct.startActivity(intent);\n        }\n    }\n\n    //control tencent meeting\n//    public static class TMAccessibilityService extends AccessibilityService{\n//        private final String TAG = MainActivity.class\n//                .getSimpleName();\n//        private final String packageName=\"com.tencent.wemeet.app:id/\";\n//\n//        @Override\n//        public void onAccessibilityEvent(AccessibilityEvent event) {\n//            Log.i(TAG, \"ACC::onAccessibilityEvent: \" + event.getEventType());\n//\n//            //TYPE_WINDOW_STATE_CHANGED == 32\n//            if (AccessibilityEvent.TYPE_WINDOW_STATE_CHANGED == event\n//                    .getEventType()) {\n//                AccessibilityNodeInfo nodeInfo = event.getSource();\n//                Log.i(TAG, \"ACC::onAccessibilityEvent: nodeInfo=\" + nodeInfo);\n//                if (nodeInfo == null) {\n//                    return;\n//                }\n//\n//                List<AccessibilityNodeInfo> list = nodeInfo\n//                        .findAccessibilityNodeInfosByViewId(packageName+\"i9\");\n//                for (AccessibilityNodeInfo node : list) {\n//                    Log.i(TAG, \"ACC::onAccessibilityEvent: left_button \" + node);\n//                    node.performAction(AccessibilityNodeInfo.ACTION_CLICK);\n//                }\n//\n//                list = nodeInfo\n//                        .findAccessibilityNodeInfosByViewId(\"android:id/button1\");\n//                for (AccessibilityNodeInfo node : list) {\n//                    Log.i(TAG, \"ACC::onAccessibilityEvent: button1 \" + node);\n//                    node.performAction(AccessibilityNodeInfo.ACTION_CLICK);\n//                }\n//            }\n//\n//        }\n//\n//        @Override\n//        public void onServiceConnected() {\n//            Log.i(TAG, \"ACC::onServiceConnected: \");\n//        }\n//        @Override\n//        public void onInterrupt() {\n//            // TODO Auto-generated method stub\n//        }\n//    };\n\n\n\n    private SensorEventListener gyroListener = new SensorEventListener() {\n        @Override\n        public void onSensorChanged(SensorEvent event) {\n            if (MicInstantMode==HandFree_mode|| MicInstantMode==Announce_Mode){\n                addSensorData(0, event.values[0], event.values[1], event.values[2], event.timestamp);\n            }\n        }\n        @Override\n        public void onAccuracyChanged(Sensor sensor, int accuracy) {\n        }\n    };\n\n    private SensorEventListener linearAccListener = new SensorEventListener() {\n        @Override\n        public void onSensorChanged(SensorEvent event) {\n            if (MicInstantMode==HandFree_mode|| MicInstantMode==Announce_Mode) {\n                addSensorData(1, event.values[0], event.values[1], event.values[2], event.timestamp);\n            }\n        }\n\n        @Override\n        public void onAccuracyChanged(Sensor sensor, int accuracy) {\n\n        }\n    };\n\n    public void addSensorData(int idx, float x, float y, float z, long timestamp) {\n        if (timestamp < lastTime[idx] + 3 * 1e6)\n            return;\n        lastTime[idx] = timestamp;\n        for (int i = 0; i < seqLength - 1; i++)\n            System.arraycopy(input[0][i + 1], 3 * idx, input[0][i], 3 * idx, 3);\n        input[0][seqLength - 1][3 * idx] = x;\n        input[0][seqLength - 1][3 * idx + 1] = y;\n        input[0][seqLength - 1][3 * idx + 2] = z;\n        if (idx == 1) {\n            if (skipNum > 0)\n                skipNum--;\n                // 进行识别\n            else {\n                recognizeFirst();\n                recognizeSecond();\n            }\n        }\n\n    }\n\n    private void recognizeFirst() {\n        int offset = 5;\n        float value = input[0][seqLength - offset][5];\n        if (value < 0.5)\n            return;\n        for (int i = 1; i <= 10; i++)\n            if (value < input[0][seqLength - offset - i][5])\n                return;\n        for (int i = 1; i < offset; i++)\n            if (value < input[0][seqLength - offset + i][5])\n                return;\n        float[][][] firstInput = new float[1][10][6];\n        float[][] firstOutput = new float[1][2];\n        for (int i = -5; i < 5; i++)\n            System.arraycopy(input[0][seqLength - offset + i], 0, firstInput[0][5 + i], 0, 6);\n        firstInterpreter.run(firstInput, firstOutput);\n        if (firstOutput[0][1] < 0.99)\n            return;\n        if (!secondFlag) {\n            secondFlag = true;\n            skipNum = 8;\n        }\n        firstTapTime = lastTime[1];\n    }\n\n    private void recognizeSecond() {\n        if (!secondFlag || skipNum > 0)\n            return;\n        if (lastTime[1] - firstTapTime > 600 * 1e6) {\n            secondFlag = false;\n            Log.e(\"Recognize\", \"!!!-1!!!\");\n            return;\n        }\n        secondInterpreter.run(input, output);\n        if (output[0][1] > output[0][0] && output[0][1] > output[0][2]) {\n            //Toast.makeText(this, \"TapTap\", Toast.LENGTH_SHORT).show();\n            //mtvTest.setText(TestText);\n            if(!MicReveseOn) {\n                changeMicState(MIC_ON);\n            }\n\n            //startTimer();\n            Log.e(\"Recognize\", \"!!!TapTap!!!\");\n        }\n        else\n            return;\n        secondFlag = false;\n        skipNum = 30;\n        for (int i = 0; i < seqLength; i++)\n            for (int j = 0; j < 6; j++)\n                input[0][i][j] = 0;\n        vibrator.vibrate(VibrationEffect.createOneShot(300, VibrationEffect.DEFAULT_AMPLITUDE));\n    }\n\n    @Override\n    protected void onDestroy() {\n        stopTimerThread();\n        if (sensorManager != null) {\n            sensorManager.unregisterListener(gyroListener);\n            sensorManager.unregisterListener(linearAccListener);\n        }\n\n        if (firstInterpreter != null) {\n            firstInterpreter.close();\n            firstInterpreter = null;\n        }\n        firstModel = null;\n\n        if (secondInterpreter != null) {\n            secondInterpreter.close();\n            secondInterpreter = null;\n        }\n        secondModel = null;\n\n        if (vibrator != null)\n            vibrator.cancel();\n        super.onDestroy();\n    }\n\n\n    //权限申请\n    private void requestMicrophonePermission() {\n        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.M) {\n            requestPermissions(\n                    new String[]{android.Manifest.permission.RECORD_AUDIO}, REQUEST_RECORD_AUDIO);\n        }\n    }\n\n    private void requestStoragePermission() {\n        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.M) {\n            requestPermissions(\n                    new String[]{Manifest.permission.READ_EXTERNAL_STORAGE,Manifest.permission.WRITE_EXTERNAL_STORAGE,Manifest.permission.RECORD_AUDIO}, REQUEST_EXTERNAL_STORAGE);\n//            requestPermissions(\n//                    new String[]{Manifest.permission.WRITE_EXTERNAL_STORAGE}, REQUEST_EXTERNAL_STORAGE);\n        }\n    }\n\n    private String assetFilePath(Context context, String assetName) {\n        File file = new File(context.getFilesDir(), assetName);\n        if (file.exists() && file.length() > 0) {\n            return file.getAbsolutePath();\n        }\n\n        try (InputStream is = context.getAssets().open(assetName)) {\n            try (OutputStream os = new FileOutputStream(file)) {\n                byte[] buffer = new byte[4 * 1024];\n                int read;\n                while ((read = is.read(buffer)) != -1) {\n                    os.write(buffer, 0, read);\n                }\n                os.flush();\n            }\n            return file.getAbsolutePath();\n        } catch (IOException e) {\n            Log.e(TAG, assetName + \": \" + e.getLocalizedMessage());\n        }\n        return null;\n    }\n\n    //刷新文件目录，使指定uri文件可见\n    private void refreshFilelist(File file){\n        Intent intent =\n                new Intent(Intent.ACTION_MEDIA_SCANNER_SCAN_FILE);\n        intent.setData(Uri.fromFile(file));\n        sendBroadcast(intent);\n    }\n\n    private void saveFile(String data,String path,String fileName) throws IOException {\n\n\n        File dir=Environment.getExternalStoragePublicDirectory(Environment.DIRECTORY_DOWNLOADS);\n        File fullpath=new File(dir,\"/myEmovo/log\");\n        if (!fullpath.exists()){\n            fullpath.mkdirs();\n        }\n\n        File file = new File(fullpath,fileName);\n        try {\n            if (!file.exists()){\n                file.createNewFile();\n            }\n        }catch (IOException e){\n            e.printStackTrace();\n        }\n\n        FileOutputStream fos = new FileOutputStream( file);\n        BufferedWriter writer = new BufferedWriter(new OutputStreamWriter(fos));\n        writer.write(data);\n        writer.flush();\n        writer.close();\n        MediaScannerConnection.scanFile(this,\n                new String[] { file.toString() }, null,\n                new MediaScannerConnection.OnScanCompletedListener() {\n                    public void onScanCompleted(String path, Uri uri) {\n                        Log.i(\"ExternalStorage\", \"Scanned \" + path + \":\");\n                        Log.i(\"ExternalStorage\", \"-> uri=\" + uri);\n                    }\n                });\n\n    }\n\n\n    private void log(float result){\n        String.valueOf(result);\n    }\n\n    private static final int REQUEST_EXTERNAL_STORAGE = 1;\n\n    private static String[] PERMISSIONS_STORAGE = {\n            \"android.permission.READ_EXTERNAL_STORAGE\", \"android.permission.WRITE_EXTERNAL_STORAGE\" };\n\n\n//    private static void verifyStoragePermissions(Activity activity) {\n//        try {\n//        //检测是否有写的权限\n//        int permission = ActivityCompat.checkSelfPermission(activity,\"android.permission.WRITE_EXTERNAL_STORAGE\");\n//            if (permission != PackageManager.PERMISSION_GRANTED) {\n//            // 没有写的权限，去申请写的权限，会弹出对话框\n//            ActivityCompat.requestPermissions(activity, PERMISSIONS_STORAGE,REQUEST_EXTERNAL_STORAGE);\n//            }\n//        } catch (Exception e) {\n//            e.printStackTrace();\n//            }\n//\n//        }\n\n\n    private void showTranslationResult(String result) {\n        mtvTest.setText(result);\n    }\n    private void changeEmoState(int EmoState){\n        int res;\n        String EmoHint=\"\";\n        if (EmoState==EMO_NEUTRAL) {\n            res = R.drawable.emoji_neutral;\n            EmoHint=\"I am satisfied!\";\n        }\n        else if(EmoState==EMO_ANGER){\n            res=R.drawable.emoji__anger;\n            EmoHint=\"I am angry!\";\n        }\n        else {\n            res=R.drawable.emoji__anger;\n            EmoHint=\"I am satisfied!\";\n        }\n        mImgvEmoState.setImageResource(res);\n        mtvEmoState.setText(EmoHint);\n\n    }\n\n\n\n    private void realtimeRecorder(){\n        android.os.Process.setThreadPriority(android.os.Process.THREAD_PRIORITY_AUDIO);\n\n        int bufferSize = AudioRecord.getMinBufferSize(SAMPLE_RATE, AudioFormat.CHANNEL_IN_MONO, AudioFormat.ENCODING_PCM_FLOAT);\n        AudioRecord record = new AudioRecord(MediaRecorder.AudioSource.DEFAULT, SAMPLE_RATE, AudioFormat.CHANNEL_IN_MONO, AudioFormat.ENCODING_PCM_FLOAT,\n                bufferSize);\n\n        if (record.getState() != AudioRecord.STATE_INITIALIZED) {\n            Log.e(LOG_TAG, \"Audio Record can't initialize!\");\n            throw new IllegalStateException();\n            //return;\n        }\n        record.startRecording();\n\n        long shortsRead = 0;\n        int recordingOffset = 0;\n        float[] audioBuffer = new float[bufferSize / 2];\n        float[] recordingBuffer = new float[RECORDING_LENGTH];\n\n        while (shortsRead < RECORDING_LENGTH/audioBuffer.length*audioBuffer.length) {\n            int numberOfShort = record.read(audioBuffer, 0, audioBuffer.length,AudioRecord.READ_NON_BLOCKING);\n            shortsRead += numberOfShort;\n            System.arraycopy(audioBuffer, 0, recordingBuffer, recordingOffset, numberOfShort);\n            recordingOffset += numberOfShort;\n        }\n\n        record.stop();\n        record.release();\n        stopTimerThread();\n\n        runOnUiThread(new Runnable() {\n            @Override\n            public void run() {\n                mtvTest.setText(\"Recognizing...\");\n            }\n        });\n\n//        int min = (int) Collections.min(Arrays.asList(recordingBuffer));\n//        int max = (int) Collections.max(Arrays.asList(recordingBuffer));\n//        System.out.println(\"最小值: \" + min);\n//        System.out.println(\"最大值: \" + max);\n\n        //send data to chaquo preprocess module\n        Python py=Python.getInstance();\n        PyObject data=py.getModule(\"DataPre\").callAttr(\"Preprocess\",recordingBuffer);\n        float[] inputfloat =data.toJava(float[].class);\n        //recognize\n        final String result = recognize(inputfloat,(int)562);\n\n        try {\n            saveFile(result,\"/logs\",\"log.txt\");\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n\n        runOnUiThread(new Runnable() {\n            @Override\n            public void run() {\n                SetProgress(mprobarEmoInference,mprobarEmoInference.getProgress(), (int) (EmoInference*100));\n                showTranslationResult(result);\n                changeEmoState(EmoState);\n                mButton.setEnabled(true);\n                mtvTest.setText(\"Recording\");\n\n            }\n        });\n\n    }\n\n    private void initVoicePrint(){\n        Thread initVPthread=new Thread(new Runnable() {\n            @Override\n            public void run() {\n                voicePrint.vpCreateGroup();\n            }\n        });\n        initVPthread.start();\n\n    }\n\n    private Runnable VoicePrint_runnable =new Runnable() {\n        @Override\n        public void run() {\n            try {\n                Log.i(TAG,\"VoicePrint_runnable: start..\");\n                toFileRecorder_byAR();\n                if (VoicePrintFlag==VoicePrint_CREATEFEATURE){\n                    voicePrint.vpCreateFeature();\n                }\n                else if(VoicePrintFlag==VoicePrint_CHECKFEATURE){\n                    voicePrint.vpSearchOneFeature();\n                }\n                else {\n                    Log.i(TAG,\"Warning:in VoicePrint_runnable empty VoicePrintFlag!\");\n                }\n\n\n            } catch (FileNotFoundException e) {\n                e.printStackTrace();\n            }\n        }\n    };\n\n    private void startVoicePrint(int VoicePrintFlag){\n        this.VoicePrintFlag=VoicePrintFlag;\n        VoicePrint_thread=new Thread(VoicePrint_runnable);\n        VoicePrint_thread.start();\n    }\n\n    private void toFileRecorder_byAR() throws FileNotFoundException {\n        android.os.Process.setThreadPriority(android.os.Process.THREAD_PRIORITY_AUDIO);\n\n        int bufferSize = AudioRecord.getMinBufferSize(SAMPLE_RATE, AudioFormat.CHANNEL_IN_MONO, AudioFormat.ENCODING_PCM_16BIT);\n        AudioRecord record = new AudioRecord(MediaRecorder.AudioSource.DEFAULT, SAMPLE_RATE, AudioFormat.CHANNEL_IN_MONO, AudioFormat.ENCODING_PCM_16BIT,\n                bufferSize);\n\n        if (record.getState() != AudioRecord.STATE_INITIALIZED) {\n            Log.e(LOG_TAG, \"Audio Record can't initialize!\");\n            throw new IllegalStateException();\n            //return;\n        }\n        record.startRecording();\n\n        long shortsRead = 0;\n        int recordingOffset = 0;\n        short[] audioBuffer = new short[bufferSize / 2];\n        short[] recordingBuffer = new short[RECORDING_LENGTH];\n\n        while (shortsRead < RECORDING_LENGTH/audioBuffer.length*audioBuffer.length) {\n            int numberOfShort = record.read(audioBuffer, 0, audioBuffer.length,AudioRecord.READ_NON_BLOCKING);\n            shortsRead += numberOfShort;\n            System.arraycopy(audioBuffer, 0, recordingBuffer, recordingOffset, numberOfShort);\n            recordingOffset += numberOfShort;\n        }\n\n        record.stop();\n        record.release();\n        //stopTimerThread();\n\n        Wave wavFile= new Wave(SAMPLE_RATE, (short) 1,recordingBuffer,0,recordingBuffer.length-1);\n        File fullpath=new File(Environment.getExternalStoragePublicDirectory(Environment.DIRECTORY_DOWNLOADS),\n                \"/myEmovo/record\");\n        if (!fullpath.exists()){\n            fullpath.mkdirs();\n        }\n        File dir=new File(fullpath,\"record.wav\");\n        //System.out.println(dir);\n        //File dir=new File(\"/data/data/org.pytorch.demo.speechrecognition/files/chaquopy/AssetFinder/app\",\"record.wav\");\n        if (!dir.exists()){\n            System.out.println(\"warning:dir not exits!\");\n        }\n        wavFile.wroteToFile(dir);\n        FileInputStream ios=new FileInputStream(dir);\n\n//        int min = (int) Collections.min(Arrays.asList(recordingBuffer));\n//        int max = (int) Collections.max(Arrays.asList(recordingBuffer));\n//        System.out.println(\"最小值: \" + min);\n//        System.out.println(\"最大值: \" + max);\n\n//        Python py=Python.getInstance();\n//        PyObject data=py.getModule(\"DataPre\").callAttr(\"Preprocess2\",ios);\n//        float[] inputfloat =data.toJava(float[].class);\n//\n//        final String result = recognize(inputfloat,(int)562);\n//        //save(result,\"log.txt\");\n//        try {\n//            saveFile(result,\"/logs\",\"log.txt\");\n//        } catch (IOException e) {\n//            e.printStackTrace();\n//        }\n//\n//        runOnUiThread(new Runnable() {\n//            @Override\n//            public void run() {\n//                showTranslationResult(result);\n//                mButton.setEnabled(true);\n//                //mTextView.setText(\"Start\");\n//            }\n//        });\n\n    }\n\n    //\n    private class MyTimerTask extends TimerTask {\n        private MediaRecorder recorder=null;\n        private File filedir=null;\n        MyTimerTask(MediaRecorder recorder,File filedir){\n            this.recorder=recorder;\n            this.filedir=filedir;\n        }\n        public void run() {\n            recorder.stop();\n            recorder.release();\n\n            Python py=Python.getInstance();\n            PyObject data=py.getModule(\"DataPre\").callAttr(\"Preprocess2\",filedir);\n            float[] inputfloat =data.toJava(float[].class);\n\n\n            final String result = recognize(inputfloat,(int)562);\n            //save(result,\"log.txt\");\n            try {\n                saveFile(result,\"/logs\",\"log.txt\");\n            } catch (IOException e) {\n                e.printStackTrace();\n            }\n\n            runOnUiThread(new Runnable() {\n                @Override\n                public void run() {\n                    showTranslationResult(result);\n                    mButton.setEnabled(true);\n                    mtvTest.setText(\"Start\");\n                }\n            });\n\n\n\n        }\n    }\n    //先将录音存为音频，再用librosa直接读取\n    private void toFileRecorder_byMR(){\n        android.os.Process.setThreadPriority(android.os.Process.THREAD_PRIORITY_AUDIO);\n        final MediaRecorder recorder = new MediaRecorder();\n        //ContentValues values = new ContentValues(3);\n        //values.put(MediaStore.MediaColumns.TITLE, fileName);\n        recorder.setAudioSource(MediaRecorder.AudioSource.MIC);\n        recorder.setOutputFormat(MediaRecorder.OutputFormat.MPEG_4);\n        recorder.setAudioEncoder(MediaRecorder.AudioEncoder.AAC);\n        //recorder.setMaxDuration(AUDIO_LEN_IN_SECOND);\n        File fullpath=new File(Environment.getExternalStoragePublicDirectory(Environment.DIRECTORY_DOWNLOADS),\n                \"/myEmovo/record\");\n        if (!fullpath.exists()){\n            fullpath.mkdirs();\n        }\n\n        File dir=new File(fullpath,\"record.m4a\");\n        recorder.setOutputFile(dir);\n        try {\n            recorder.prepare();\n        } catch (Exception e){\n            e.printStackTrace();\n            while (true){\n                System.out.println(\"prepare wrong!\");\n            }\n\n        }\n        recorder.start();\n\n        Timer timer = new Timer();\n        timer.schedule(new MyTimerTask(recorder,dir), 2000, 5000);\n    }\n\n    public void run() {\n        Log.i(TAG,\"recorder running...\");\n        //toFileRecorder_byMR();\n        //realtimeRecorder();\n//        try {\n//            toFileRecorder_byAR();\n//        } catch (FileNotFoundException e) {\n//            e.printStackTrace();\n//        }\n\n    }\n\n    private String recognize(float[] floatInputBuffer,int shape0) {\n        if (mModuleEncoder == null) {\n\n            mModuleEncoder = LiteModuleLoader.load(assetFilePath(getApplicationContext(), \"Model2.ptl\"));\n        }\n        int Length=floatInputBuffer.length;\n        double wav2vecinput[] = new double[Length];\n        for (int n = 0; n < Length; n++)\n            wav2vecinput[n] = floatInputBuffer[n];\n\n        FloatBuffer inTensorBuffer = Tensor.allocateFloatBuffer(Length);\n        for (double val : wav2vecinput)\n            inTensorBuffer.put((float)val);\n\n        Tensor inTensor = Tensor.fromBlob(inTensorBuffer, new long[]{(int)Length/shape0,(int)Length/shape0, shape0});\n        Tensor ResultTensor=mModuleEncoder.forward(IValue.from(inTensor)).toTensor();\n        float[] ResultFloat=ResultTensor.getDataAsFloatArray();\n        float result =ResultFloat[0]/(ResultFloat[0]+ResultFloat[1]);\n        this.EmoInference=result;\n        if (result<0.5){\n            this.EmoState=EMO_NEUTRAL;\n        }\n        else if (result>0.5){\n            this.EmoState=EMO_ANGER;\n        }\n\n\n        return String.valueOf(result);\n    }\n\n    public void SetProgress(final ProgressBar view, int startprogress, int endprogress) {//进度条的控件，以及起始的值\n\n        view.setVisibility(View.VISIBLE);\n\n\n        ValueAnimator animator = ValueAnimator.ofInt(startprogress, endprogress).setDuration(800);\n\n        animator.addUpdateListener(new ValueAnimator.AnimatorUpdateListener() {\n            @Override\n            public void onAnimationUpdate(ValueAnimator valueAnimator) {\n                view.setProgress((int) valueAnimator.getAnimatedValue());\n            }\n        });\n        animator.start();\n    }\n\n    public void toast(CharSequence cs) {\n        Toast.makeText(this, cs, Toast.LENGTH_SHORT).show();\n    }\n\n}
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/app/src/main/java/org/pytorch/demo/speechrecognition/MainActivity.java b/app/src/main/java/org/pytorch/demo/speechrecognition/MainActivity.java
--- a/app/src/main/java/org/pytorch/demo/speechrecognition/MainActivity.java	(revision 5205d2535d26021f98334bd1036174b1fe12aab5)
+++ b/app/src/main/java/org/pytorch/demo/speechrecognition/MainActivity.java	(date 1654413057286)
@@ -72,6 +72,7 @@
 import java.nio.FloatBuffer;
 import java.nio.MappedByteBuffer;
 import java.text.BreakIterator;
+import java.util.Date;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Locale;
@@ -89,8 +90,13 @@
 import org.tensorflow.lite.Interpreter;
 import org.tensorflow.lite.support.common.FileUtil;
 
-
-
+import com.zlw.main.recorderlib.RecordManager;
+import com.zlw.main.recorderlib.recorder.RecordConfig;
+import com.zlw.main.recorderlib.recorder.RecordHelper;
+import com.zlw.main.recorderlib.recorder.listener.RecordFftDataListener;
+import com.zlw.main.recorderlib.recorder.listener.RecordResultListener;
+import com.zlw.main.recorderlib.recorder.listener.RecordSoundSizeListener;
+import com.zlw.main.recorderlib.recorder.listener.RecordStateListener;
 
 public class MainActivity extends AppCompatActivity implements Runnable {
     private static final String TAG = MainActivity.class.getName();
@@ -105,7 +111,6 @@
     private ProgressBar mprobarEmoInference;
     private boolean mButtonisPlay=false;
 
-
     private int EmoState=EMO_NEUTRAL;
     private float EmoInference=0;
 
@@ -170,6 +175,9 @@
     public static int MicState=MIC_OFF;
     private static boolean MicReveseOn=false;//仅在倒置开麦的情况下触发正置关麦
 
+    final RecordManager mRecordManager = RecordManager.getInstance();
+    private String recordString = "";
+
     private TextView mtvMicInstantMode;
 
     private SoundPool soundPool;
@@ -183,6 +191,7 @@
     Thread FloatingWindow_thread;
     Thread SpeechDetector_thread;
     Thread VoicePrint_thread;
+    Thread Record_thread;
     //Thread MicOnTimer_thread;
 
     private HandlerThread MicOnTimerThread;
@@ -203,6 +212,8 @@
 
     private VoicePrint voicePrint=new VoicePrint();
 
+    private int VoicePrintRcd=VoicePrint_CREATEFEATURE;
+
 
 
     //private TMAccessibilityService TMcontrol=new TMAccessibilityService();
@@ -338,7 +349,8 @@
         mtvMicInstantMode = findViewById(R.id.tvMicInstantMode);
         mprobarEmoInference.setProgress(1);
 
-        //initVoicePrint();
+        initVoicePrint();
+        initRecorder();
         startMicOnTimer();
 
         mButton.setOnClickListener(new View.OnClickListener() {
@@ -396,7 +408,7 @@
         //initSpeechDetector();
         Log.i(TAG, "Main::oncreate done ");
 
-        Utils.writeTxtToFile(Utils.GetSystemTime()+" "+"Main::oncreate done ","/logs","/log.txt");
+        // Utils.writeTxtToFile(Utils.GetSystemTime()+" "+"Main::oncreate done ","/logs","/log.txt");
         //startTimer();
 
         //initAccessibility(this.getApplicationContext(),"TMAccessibilityService");
@@ -550,7 +562,7 @@
                 if(!MicReveseOn) {
                     MicReveseOn=true;
                     changeMicState(MIC_ON);
-                    Utils.writeTxtToFile(Utils.GetSystemTime()+" "+"Main::oncreate done ","/logs","/log.txt");
+                    // Utils.writeTxtToFile(Utils.GetSystemTime()+" "+"Main::oncreate done ","/logs","/log.txt");
                     Log.i(TAG, "CheckGesture:Phone reverted");
                 }
                 if (CheckMicOnTimerRunning()) {
@@ -590,14 +602,15 @@
 
                     res = R.drawable.mic_on;
                     if (TmAccessibilityService.mService.CheckMicOn() == 0) {
-                        TmAccessibilityService.mService.ClickView(TmAccessibilityService.mService.vid_InMeeting_Mic);
+                        TmAccessibilityService.mService.ClickView(TmAccessibilityService.vid_InMeeting_Mic);
                     }
                     TmAccessibilityService.mService.SetMicMute(false);
                     ChaneMicOnTimerState(MicOnTimerState_ACTIVE);
 
                     MicState = MIC_ON;
                     soundPool.play(1, 1, 1, 0, 0, 1);
-
+                    mRecordManager.start();
+                    startTimer();
                     MicHint = "Microphone ON!";
 
 
@@ -612,6 +625,8 @@
                     MicState = MIC_OFF;
                     MicReveseOn=false;
                     soundPool.play(2, 1, 1, 0, 0, 1);
+                    stopTimer();
+                    mRecordManager.stop();
                     MicHint = "Microphone OFF!";
                 } else {
                     MicState = MIC_OFF;
@@ -624,6 +639,8 @@
                     ChaneMicOnTimerState(MicOnTimerState_INACTIVE);
 
                     MicReveseOn=false;
+                    stopTimer();
+                    mRecordManager.stop();
                     MicHint = "Microphone OFF!";
                 }
                 mImgvEmoState.setImageResource(res);
@@ -709,9 +726,12 @@
             TimerHandler.postDelayed(TimerRunnable, 1000);
             Timer_time+=1;
             Log.e(TAG, "Timer running");
-            if(Timer_time>5){
-                stopTimer();
+            if(Timer_time>3){
+                // stopTimer();
                 Log.i(TAG,"Timer:"+Timer_time);
+                mRecordManager.stop();
+                Timer_time=0;
+                mRecordManager.start();
                 //speechRecognizer.stopListening();
             }
         }
@@ -722,7 +742,7 @@
             TimerThread.join();
             TimerThread = null;
             TimerHandler = null;
-            speechRecognizer.stopListening();
+            // speechRecognizer.stopListening();
             Timer_time = 0;
         } catch (InterruptedException e) {
             Log.e(TAG, "Error on stopping background thread", e);
@@ -1076,74 +1096,74 @@
 
 
 
-    private void realtimeRecorder(){
-        android.os.Process.setThreadPriority(android.os.Process.THREAD_PRIORITY_AUDIO);
-
-        int bufferSize = AudioRecord.getMinBufferSize(SAMPLE_RATE, AudioFormat.CHANNEL_IN_MONO, AudioFormat.ENCODING_PCM_FLOAT);
-        AudioRecord record = new AudioRecord(MediaRecorder.AudioSource.DEFAULT, SAMPLE_RATE, AudioFormat.CHANNEL_IN_MONO, AudioFormat.ENCODING_PCM_FLOAT,
-                bufferSize);
-
-        if (record.getState() != AudioRecord.STATE_INITIALIZED) {
-            Log.e(LOG_TAG, "Audio Record can't initialize!");
-            throw new IllegalStateException();
-            //return;
-        }
-        record.startRecording();
-
-        long shortsRead = 0;
-        int recordingOffset = 0;
-        float[] audioBuffer = new float[bufferSize / 2];
-        float[] recordingBuffer = new float[RECORDING_LENGTH];
-
-        while (shortsRead < RECORDING_LENGTH/audioBuffer.length*audioBuffer.length) {
-            int numberOfShort = record.read(audioBuffer, 0, audioBuffer.length,AudioRecord.READ_NON_BLOCKING);
-            shortsRead += numberOfShort;
-            System.arraycopy(audioBuffer, 0, recordingBuffer, recordingOffset, numberOfShort);
-            recordingOffset += numberOfShort;
-        }
-
-        record.stop();
-        record.release();
-        stopTimerThread();
-
-        runOnUiThread(new Runnable() {
-            @Override
-            public void run() {
-                mtvTest.setText("Recognizing...");
-            }
-        });
-
-//        int min = (int) Collections.min(Arrays.asList(recordingBuffer));
-//        int max = (int) Collections.max(Arrays.asList(recordingBuffer));
-//        System.out.println("最小值: " + min);
-//        System.out.println("最大值: " + max);
-
-        //send data to chaquo preprocess module
-        Python py=Python.getInstance();
-        PyObject data=py.getModule("DataPre").callAttr("Preprocess",recordingBuffer);
-        float[] inputfloat =data.toJava(float[].class);
-        //recognize
-        final String result = recognize(inputfloat,(int)562);
-
-        try {
-            saveFile(result,"/logs","log.txt");
-        } catch (IOException e) {
-            e.printStackTrace();
-        }
-
-        runOnUiThread(new Runnable() {
-            @Override
-            public void run() {
-                SetProgress(mprobarEmoInference,mprobarEmoInference.getProgress(), (int) (EmoInference*100));
-                showTranslationResult(result);
-                changeEmoState(EmoState);
-                mButton.setEnabled(true);
-                mtvTest.setText("Recording");
-
-            }
-        });
-
-    }
+//    private void realtimeRecorder(){
+//        android.os.Process.setThreadPriority(android.os.Process.THREAD_PRIORITY_AUDIO);
+//
+//        int bufferSize = AudioRecord.getMinBufferSize(SAMPLE_RATE, AudioFormat.CHANNEL_IN_MONO, AudioFormat.ENCODING_PCM_FLOAT);
+//        AudioRecord record = new AudioRecord(MediaRecorder.AudioSource.DEFAULT, SAMPLE_RATE, AudioFormat.CHANNEL_IN_MONO, AudioFormat.ENCODING_PCM_FLOAT,
+//                bufferSize);
+//
+//        if (record.getState() != AudioRecord.STATE_INITIALIZED) {
+//            Log.e(LOG_TAG, "Audio Record can't initialize!");
+//            throw new IllegalStateException();
+//            //return;
+//        }
+//        record.startRecording();
+//
+//        long shortsRead = 0;
+//        int recordingOffset = 0;
+//        float[] audioBuffer = new float[bufferSize / 2];
+//        float[] recordingBuffer = new float[RECORDING_LENGTH];
+//
+//        while (shortsRead < RECORDING_LENGTH/audioBuffer.length*audioBuffer.length) {
+//            int numberOfShort = record.read(audioBuffer, 0, audioBuffer.length,AudioRecord.READ_NON_BLOCKING);
+//            shortsRead += numberOfShort;
+//            System.arraycopy(audioBuffer, 0, recordingBuffer, recordingOffset, numberOfShort);
+//            recordingOffset += numberOfShort;
+//        }
+//
+//        record.stop();
+//        record.release();
+//        stopTimerThread();
+//
+//        runOnUiThread(new Runnable() {
+//            @Override
+//            public void run() {
+//                mtvTest.setText("Recognizing...");
+//            }
+//        });
+//
+////        int min = (int) Collections.min(Arrays.asList(recordingBuffer));
+////        int max = (int) Collections.max(Arrays.asList(recordingBuffer));
+////        System.out.println("最小值: " + min);
+////        System.out.println("最大值: " + max);
+//
+//        //send data to chaquo preprocess module
+//        Python py=Python.getInstance();
+//        PyObject data=py.getModule("DataPre").callAttr("Preprocess",recordingBuffer);
+//        float[] inputfloat =data.toJava(float[].class);
+//        //recognize
+//        final String result = recognize(inputfloat,(int)562);
+//
+//        try {
+//            saveFile(result,"/logs","log.txt");
+//        } catch (IOException e) {
+//            e.printStackTrace();
+//        }
+//
+//        runOnUiThread(new Runnable() {
+//            @Override
+//            public void run() {
+//                SetProgress(mprobarEmoInference,mprobarEmoInference.getProgress(), (int) (EmoInference*100));
+//                showTranslationResult(result);
+//                changeEmoState(EmoState);
+//                mButton.setEnabled(true);
+//                mtvTest.setText("Recording");
+//
+//            }
+//        });
+//
+//    }
 
     private void initVoicePrint(){
         Thread initVPthread=new Thread(new Runnable() {
@@ -1156,22 +1176,65 @@
 
     }
 
+    private void initRecorder(){
+        Thread initRCthread = new Thread(new Runnable() {
+            @Override
+            public void run() {
+                mRecordManager.init(MyApp.getInstance(), true);
+                mRecordManager.changeFormat(RecordConfig.RecordFormat.MP3);
+                String recordDir = String.format(Locale.getDefault(), "%s/Record/",
+                        Environment.getExternalStorageDirectory().getAbsolutePath());
+                mRecordManager.changeRecordDir(recordDir);
+                initRecordEvent();
+            }
+        });
+        initRCthread.run();
+    }
+
+    private void initRecordEvent() {
+        Log.i(TAG,"InitRecord!");
+        mRecordManager.setRecordStateListener(new RecordStateListener() {
+            @Override
+            public void onStateChange(RecordHelper.RecordState state) {
+                Log.i(TAG, "onStateChange " + state.name());
+            }
+
+            @Override
+            public void onError(String error) {
+                Log.i(TAG, "onError " + error);
+            }
+        });
+        mRecordManager.setRecordResultListener(new RecordResultListener() {
+            @Override
+            public void onResult(File result) {
+                recordString = result.getAbsolutePath();
+                Log.i(TAG, "onResult "+recordString);
+                startVoicePrint(VoicePrintRcd);
+            }
+        });
+    }
+
     private Runnable VoicePrint_runnable =new Runnable() {
         @Override
         public void run() {
             try {
                 Log.i(TAG,"VoicePrint_runnable: start..");
                 toFileRecorder_byAR();
+                String audioPath = recordString;
+                Log.i(TAG,"Using audio path: "+audioPath);
                 if (VoicePrintFlag==VoicePrint_CREATEFEATURE){
-                    voicePrint.vpCreateFeature();
+                    voicePrint.vpCreateFeature(audioPath);
                 }
                 else if(VoicePrintFlag==VoicePrint_CHECKFEATURE){
-                    voicePrint.vpSearchOneFeature();
+                    voicePrint.vpSearchOneFeature(audioPath);
                 }
                 else {
                     Log.i(TAG,"Warning:in VoicePrint_runnable empty VoicePrintFlag!");
                 }
-
+                File toDelete = new File(audioPath);
+                if(toDelete.delete()){
+                    Log.i(TAG,"deleted origin file "+audioPath);
+                }
 
             } catch (FileNotFoundException e) {
                 e.printStackTrace();
Index: app/src/main/java/org/pytorch/demo/speechrecognition/MyApp.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>package org.pytorch.demo.speechrecognition;\n\nimport android.app.Application;\n\npublic class MyApp extends Application {\n    public static MyApp mApp;\n\n    @Override\n    public void onCreate() {\n        super.onCreate();\n        mApp = this;\n    }\n}
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/app/src/main/java/org/pytorch/demo/speechrecognition/MyApp.java b/app/src/main/java/org/pytorch/demo/speechrecognition/MyApp.java
--- a/app/src/main/java/org/pytorch/demo/speechrecognition/MyApp.java	(revision 5205d2535d26021f98334bd1036174b1fe12aab5)
+++ b/app/src/main/java/org/pytorch/demo/speechrecognition/MyApp.java	(date 1654413057290)
@@ -1,8 +1,8 @@
 package org.pytorch.demo.speechrecognition;
 
-import android.app.Application;
+import com.chaquo.python.android.PyApplication;
 
-public class MyApp extends Application {
+public class MyApp extends PyApplication {
     public static MyApp mApp;
 
     @Override
@@ -10,4 +10,6 @@
         super.onCreate();
         mApp = this;
     }
+
+    public static MyApp getInstance() { return mApp;}
 }
\ No newline at end of file
Index: build.gradle
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>// Top-level build file where you can add configuration options common to all sub-projects/modules.\nbuildscript {\n    repositories {\n        google()\n        jcenter()\n        maven { url \"https://chaquo.com/maven\" }\n    }\n    dependencies {\n        classpath \"com.android.tools.build:gradle:4.0.1\"\n        classpath \"com.chaquo.python:gradle:10.0.1\"\n        // NOTE: Do not place your application dependencies here; they belong\n        // in the individual module build.gradle files\n    }\n}\n\nallprojects {\n    repositories {\n        google()\n        jcenter()\n    }\n}\n\ntask clean(type: Delete) {\n    delete rootProject.buildDir\n}
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/build.gradle b/build.gradle
--- a/build.gradle	(revision 5205d2535d26021f98334bd1036174b1fe12aab5)
+++ b/build.gradle	(date 1654413057308)
@@ -7,6 +7,8 @@
     }
     dependencies {
         classpath "com.android.tools.build:gradle:4.0.1"
+        classpath 'com.github.dcendents:android-maven-gradle-plugin:2.0'
+        // classpath 'com.jakewharton:butterknife-gradle-plugin:8.8.1'
         classpath "com.chaquo.python:gradle:10.0.1"
         // NOTE: Do not place your application dependencies here; they belong
         // in the individual module build.gradle files
Index: .idea/runConfigurations.xml
===================================================================
diff --git a/.idea/runConfigurations.xml b/.idea/runConfigurations.xml
deleted file mode 100644
--- a/.idea/runConfigurations.xml	(revision 5205d2535d26021f98334bd1036174b1fe12aab5)
+++ /dev/null	(revision 5205d2535d26021f98334bd1036174b1fe12aab5)
@@ -1,12 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<project version="4">
-  <component name="RunConfigurationProducerService">
-    <option name="ignoredProducers">
-      <set>
-        <option value="org.jetbrains.plugins.gradle.execution.test.runner.AllInPackageGradleConfigurationProducer" />
-        <option value="org.jetbrains.plugins.gradle.execution.test.runner.TestClassGradleConfigurationProducer" />
-        <option value="org.jetbrains.plugins.gradle.execution.test.runner.TestMethodGradleConfigurationProducer" />
-      </set>
-    </option>
-  </component>
-</project>
\ No newline at end of file
Index: .idea/gradle.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project version=\"4\">\n  <component name=\"GradleMigrationSettings\" migrationVersion=\"1\" />\n  <component name=\"GradleSettings\">\n    <option name=\"linkedExternalProjectsSettings\">\n      <GradleProjectSettings>\n        <option name=\"testRunner\" value=\"PLATFORM\" />\n        <option name=\"distributionType\" value=\"DEFAULT_WRAPPED\" />\n        <option name=\"externalProjectPath\" value=\"$PROJECT_DIR$\" />\n        <option name=\"gradleJvm\" value=\"1.8\" />\n        <option name=\"modules\">\n          <set>\n            <option value=\"$PROJECT_DIR$\" />\n            <option value=\"$PROJECT_DIR$/app\" />\n          </set>\n        </option>\n        <option name=\"resolveModulePerSourceSet\" value=\"false\" />\n      </GradleProjectSettings>\n    </option>\n  </component>\n</project>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/gradle.xml b/.idea/gradle.xml
--- a/.idea/gradle.xml	(revision 5205d2535d26021f98334bd1036174b1fe12aab5)
+++ b/.idea/gradle.xml	(date 1654413057295)
@@ -4,7 +4,7 @@
   <component name="GradleSettings">
     <option name="linkedExternalProjectsSettings">
       <GradleProjectSettings>
-        <option name="testRunner" value="PLATFORM" />
+        <option name="testRunner" value="GRADLE" />
         <option name="distributionType" value="DEFAULT_WRAPPED" />
         <option name="externalProjectPath" value="$PROJECT_DIR$" />
         <option name="gradleJvm" value="1.8" />
@@ -12,6 +12,7 @@
           <set>
             <option value="$PROJECT_DIR$" />
             <option value="$PROJECT_DIR$/app" />
+            <option value="$PROJECT_DIR$/recorderlib" />
           </set>
         </option>
         <option name="resolveModulePerSourceSet" value="false" />
Index: .idea/compiler.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/compiler.xml b/.idea/compiler.xml
new file mode 100644
--- /dev/null	(date 1654413057297)
+++ b/.idea/compiler.xml	(date 1654413057297)
@@ -0,0 +1,6 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<project version="4">
+  <component name="CompilerConfiguration">
+    <bytecodeTargetLevel target="1.8" />
+  </component>
+</project>
\ No newline at end of file
Index: settings.gradle
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>include ':app'\nrootProject.name = \"SpeechRecognition\"
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/settings.gradle b/settings.gradle
--- a/settings.gradle	(revision 5205d2535d26021f98334bd1036174b1fe12aab5)
+++ b/settings.gradle	(date 1654413057299)
@@ -1,2 +1,2 @@
-include ':app'
+include ':app', ':recorderlib'
 rootProject.name = "SpeechRecognition"
\ No newline at end of file
Index: app/src/main/java/org/pytorch/demo/speechrecognition/iflytek/CreateFeature.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>package org.pytorch.demo.speechrecognition.iflytek;\n\nimport com.alibaba.fastjson.JSON;\nimport com.alibaba.fastjson.JSONObject;\nimport com.google.gson.Gson;\n\nimport javax.crypto.Mac;\nimport javax.crypto.spec.SecretKeySpec;\nimport java.io.*;\nimport java.net.HttpURLConnection;\nimport java.net.URL;\nimport java.net.URLConnection;\nimport java.net.URLEncoder;\nimport java.nio.charset.Charset;\nimport java.text.SimpleDateFormat;\nimport java.util.Base64;\nimport java.util.Date;\nimport java.util.Locale;\nimport java.util.TimeZone;\n\n/**\n * 添加音频特征\n */\npublic class CreateFeature {\n    private String requestUrl;\n    private String APPID;\n    private String apiSecret;\n    private String apiKey;\n\n    private String GroupID=\"\";\n    private String FeatureID=\"\";\n    //音频存放位置\n    private static String AUDIO_PATH;\n    //解析Json\n    private static Gson json = new Gson();\n\n    //构造函数,为成员变量赋值\n    public CreateFeature(String requestUrl,String APPID,String apiSecret,String apiKey,String GroupID,String FeatureID,String AUDIO_PATH){\n        this.requestUrl=requestUrl;\n        this.APPID=APPID;\n        this.apiSecret=apiSecret;\n        this.apiKey=apiKey;\n        this.AUDIO_PATH=AUDIO_PATH;\n        this.GroupID=GroupID;\n        this.FeatureID=FeatureID;\n    }\n    //提供给主函数调用的方法\n    public static void doCreateFeature(String requestUrl,String APPID,String apiSecret,String apiKey,String GroupID,String FeatureID,String AUDIO_PATH){\n        CreateFeature createFeature = new CreateFeature(requestUrl,APPID,apiSecret,apiKey,GroupID,FeatureID,AUDIO_PATH);\n        try {\n            String resp = createFeature.doRequest();\n            System.out.println(\"resp=>\"+resp);\n            JsonParse myJsonParse = json.fromJson(resp, JsonParse.class);\n            String textBase64Decode=new String(Base64.getDecoder().decode(myJsonParse.payload.createFeatureRes.text), \"UTF-8\");\n            JSONObject jsonObject = JSON.parseObject(textBase64Decode);\n            System.out.println(\"text字段Base64解码后=>\"+jsonObject);\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n    /**\n     * 请求主方法\n     * @return 返回服务结果\n     * @throws Exception 异常\n     */\n    public String doRequest() throws Exception {\n        URL realUrl = new URL(buildRequetUrl());\n        URLConnection connection = realUrl.openConnection();\n        HttpURLConnection httpURLConnection = (HttpURLConnection) connection;\n        httpURLConnection.setDoInput(true);\n        httpURLConnection.setDoOutput(true);\n        httpURLConnection.setRequestMethod(\"POST\");\n        httpURLConnection.setRequestProperty(\"Content-type\",\"application/json\");\n\n        OutputStream out = httpURLConnection.getOutputStream();\n        String params = buildParam();\n        System.out.println(\"params=>\"+params);\n        out.write(params.getBytes());\n        out.flush();\n        InputStream is = null;\n        try{\n            is = httpURLConnection.getInputStream();\n        }catch (Exception e){\n            is = httpURLConnection.getErrorStream();\n            throw new Exception(\"make request error:\"+\"code is \"+httpURLConnection.getResponseMessage()+readAllBytes(is));\n        }\n        return readAllBytes(is);\n    }\n\n    /**\n     * 处理请求URL\n     * 封装鉴权参数等\n     * @return 处理后的URL\n     */\n    public String buildRequetUrl(){\n        URL url = null;\n        // 替换调schema前缀 ，原因是URL库不支持解析包含ws,wss schema的url\n        String  httpRequestUrl = requestUrl.replace(\"ws://\", \"http://\").replace(\"wss://\",\"https://\" );\n        try {\n            url = new URL(httpRequestUrl);\n            //获取当前日期并格式化\n            SimpleDateFormat format = new SimpleDateFormat(\"EEE, dd MMM yyyy HH:mm:ss z\", Locale.US);\n            format.setTimeZone(TimeZone.getTimeZone(\"GMT\"));\n            String date = format.format(new Date());\n\n            String host = url.getHost();\n            if (url.getPort()!=80 && url.getPort() !=443){\n                host = host +\":\"+String.valueOf(url.getPort());\n            }\n            StringBuilder builder = new StringBuilder(\"host: \").append(host).append(\"\\n\").//\n                    append(\"date: \").append(date).append(\"\\n\").//\n                    append(\"POST \").append(url.getPath()).append(\" HTTP/1.1\");\n            Charset charset = Charset.forName(\"UTF-8\");\n            Mac mac = Mac.getInstance(\"hmacsha256\");\n            SecretKeySpec spec = new SecretKeySpec(apiSecret.getBytes(charset), \"hmacsha256\");\n            mac.init(spec);\n            byte[] hexDigits = mac.doFinal(builder.toString().getBytes(charset));\n            String sha = Base64.getEncoder().encodeToString(hexDigits);\n\n            String authorization = String.format(\"api_key=\\\"%s\\\", algorithm=\\\"%s\\\", headers=\\\"%s\\\", signature=\\\"%s\\\"\", apiKey, \"hmac-sha256\", \"host date request-line\", sha);\n            String authBase = Base64.getEncoder().encodeToString(authorization.getBytes(charset));\n            return String.format(\"%s?authorization=%s&host=%s&date=%s\", requestUrl, URLEncoder.encode(authBase), URLEncoder.encode(host), URLEncoder.encode(date));\n\n        } catch (Exception e) {\n            throw new RuntimeException(\"assemble requestUrl error:\"+e.getMessage());\n        }\n    }\n\n    /**\n     * 组装请求参数\n     * 直接使用示例参数，\n     * 替换部分值\n     * @return 参数字符串\n     */\n    private String  buildParam() throws IOException {\n        String param = \"{\"+\n                \"    \\\"header\\\": {\"+\n                \"        \\\"app_id\\\": \\\"\"+APPID+\"\\\",\"+\n                \"        \\\"status\\\": 3\"+\n                \"    },\"+\n                \"    \\\"parameter\\\": {\"+\n                \"        \\\"s782b4996\\\": {\"+\n                \"            \\\"func\\\": \\\"createFeature\\\",\"+\n                //这里填上所需要的groupId\n                \"            \\\"groupId\\\": \\\"iFLYTEK_examples_groupId\\\",\"+\n                //这里填上所需要的featureId\n                \"            \\\"featureId\\\": \\\"iFLYTEK_examples_featureId\\\",\"+\n                //这里填上所需要的featureInfo\n                \"            \\\"featureInfo\\\": \\\"iFLYTEK_examples_featureInfo\\\",\"+\n                \"            \\\"createFeatureRes\\\": {\"+\n                \"                \\\"encoding\\\": \\\"utf8\\\",\"+\n                \"                \\\"compress\\\": \\\"raw\\\",\"+\n                \"                \\\"format\\\": \\\"json\\\"\"+\n                \"            }\"+\n                \"        }\"+\n                \"    },\"+\n                \"\\\"payload\\\":{\"+\n                \"    \\\"resource\\\": {\"+\n                //这里根据不同的音频编码填写不同的编码格式\n                \"        \\\"encoding\\\": \\\"lame\\\",\"+\n                \"        \\\"sample_rate\\\": 16000,\"+\n                \"        \\\"channels\\\": 1,\"+\n                \"        \\\"bit_depth\\\": 16,\"+\n                \"        \\\"status\\\": 3,\"+\n                \"        \\\"audio\\\": \\\"\"+Base64.getEncoder().encodeToString(read(AUDIO_PATH))+\"\\\"\"+\n                \"    }}\"+\n                \"}\";\n        return param;\n    }\n\n    /**\n     * 读取流数据\n     * @param is 流\n     * @return 字符串\n     * @throws IOException 异常\n     */\n    private String readAllBytes(InputStream is) throws IOException {\n        byte[] b = new byte[1024];\n        StringBuilder sb = new StringBuilder();\n        int len = 0;\n        while ((len = is.read(b)) != -1){\n            sb.append(new String(b, 0, len, \"utf-8\"));\n        }\n        return sb.toString();\n    }\n\n    public static byte[] read(String filePath) throws IOException {\n        InputStream in = new FileInputStream(filePath);\n        byte[] data = inputStream2ByteArray(in);\n        in.close();\n        return data;\n    }\n    private static byte[] inputStream2ByteArray(InputStream in) throws IOException {\n        ByteArrayOutputStream out = new ByteArrayOutputStream();\n        byte[] buffer = new byte[1024 * 4];\n        int n = 0;\n        while ((n = in.read(buffer)) != -1) {\n            out.write(buffer, 0, n);\n        }\n        return out.toByteArray();\n    }\n    //Json解析\n    class JsonParse {\n        public Header header;\n        public Payload payload;\n    }\n    class Header{\n        public int code;\n        public String message;\n        public String sid;\n        public int status;\n    }\n    class Payload{\n        //根据model的取值不同,名字有所变动。\n        public CreateFeatureRes createFeatureRes;\n    }\n    class CreateFeatureRes{\n        public String compress;\n        public String encoding;\n        public String format;\n        public String text;\n    }\n}\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/app/src/main/java/org/pytorch/demo/speechrecognition/iflytek/CreateFeature.java b/app/src/main/java/org/pytorch/demo/speechrecognition/iflytek/CreateFeature.java
--- a/app/src/main/java/org/pytorch/demo/speechrecognition/iflytek/CreateFeature.java	(revision 5205d2535d26021f98334bd1036174b1fe12aab5)
+++ b/app/src/main/java/org/pytorch/demo/speechrecognition/iflytek/CreateFeature.java	(date 1654413057302)
@@ -64,7 +64,7 @@
      * @throws Exception 异常
      */
     public String doRequest() throws Exception {
-        URL realUrl = new URL(buildRequetUrl());
+        URL realUrl = new URL(buildRequestUrl());
         URLConnection connection = realUrl.openConnection();
         HttpURLConnection httpURLConnection = (HttpURLConnection) connection;
         httpURLConnection.setDoInput(true);
@@ -92,7 +92,7 @@
      * 封装鉴权参数等
      * @return 处理后的URL
      */
-    public String buildRequetUrl(){
+    public String buildRequestUrl(){
         URL url = null;
         // 替换调schema前缀 ，原因是URL库不支持解析包含ws,wss schema的url
         String  httpRequestUrl = requestUrl.replace("ws://", "http://").replace("wss://","https://" );
@@ -142,11 +142,11 @@
                 "        \"s782b4996\": {"+
                 "            \"func\": \"createFeature\","+
                 //这里填上所需要的groupId
-                "            \"groupId\": \"iFLYTEK_examples_groupId\","+
+                "            \"groupId\": \""+GroupID+"\","+
                 //这里填上所需要的featureId
-                "            \"featureId\": \"iFLYTEK_examples_featureId\","+
+                "            \"featureId\": \""+FeatureID+"\","+
                 //这里填上所需要的featureInfo
-                "            \"featureInfo\": \"iFLYTEK_examples_featureInfo\","+
+                "            \"featureInfo\": \"example_feature\","+
                 "            \"createFeatureRes\": {"+
                 "                \"encoding\": \"utf8\","+
                 "                \"compress\": \"raw\","+
Index: app/build.gradle
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>apply plugin: 'com.android.application'\napply plugin: 'com.chaquo.python'\nrepositories {\n    jcenter()\n    maven {\n        url \"https://oss.sonatype.org/content/repositories/snapshots\"\n    }\n}\n\nandroid {\n    compileSdkVersion 30\n    buildToolsVersion \"30.0.2\"\n\n    lintOptions {\n        checkReleaseBuilds false\n        // Or, if you prefer, you can continue to check for errors in release builds,\n        // but continue the build even when errors are found:\n        abortOnError false\n    }\n\n    defaultConfig {\n        applicationId \"org.pytorch.demo.speechrecognition\"\n        minSdkVersion 28\n        targetSdkVersion 30\n        versionCode 1\n        versionName \"1.0\"\n        ndk {\n            abiFilters \"armeabi-v7a\", \"arm64-v8a\", \"x86\", \"x86_64\"\n        }\n        python{\n            buildPython \"C:\\\\Users\\\\sy\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37\\\\python.exe\"\n        }\n        python{\n            pip{\n                install \"librosa==0.8.1\"\n                install \"numpy\"\n            }\n        }\n        testInstrumentationRunner \"androidx.test.runner.AndroidJUnitRunner\"\n    }\n\n    buildTypes {\n        release {\n            minifyEnabled false\n            proguardFiles getDefaultProguardFile('proguard-android-optimize.txt')\n        }\n    }\n    compileOptions {\n        sourceCompatibility JavaVersion.VERSION_1_8\n        targetCompatibility JavaVersion.VERSION_1_8\n    }\n    aaptOptions {\n        noCompress \"tflite\"\n    }\n}\n\ndependencies {\n    implementation 'androidx.appcompat:appcompat:1.2.0'\n    implementation 'androidx.constraintlayout:constraintlayout:2.0.4'\n    implementation files('libs\\\\TarsosDSP-Android-latest.jar')\n    implementation 'com.google.android.material:material:1.0.0'\n    implementation 'androidx.navigation:navigation-fragment:2.1.0'\n    implementation 'androidx.navigation:navigation-ui:2.1.0'\n    implementation 'androidx.lifecycle:lifecycle-extensions:2.1.0'\n    testImplementation 'junit:junit:4.12'\n    androidTestImplementation 'androidx.test.ext:junit:1.1.2'\n    androidTestImplementation 'androidx.test.espresso:espresso-core:3.3.0'\n\n    implementation 'org.pytorch:pytorch_android_lite:1.9.0'\n    implementation('org.tensorflow:tensorflow-lite:0.0.0-nightly') { changing = true }\n    implementation('org.tensorflow:tensorflow-lite-support:0.0.0-nightly') { changing = true }\n    implementation('com.alibaba:fastjson:1.1.72.android')\n    implementation 'com.google.code.gson:gson:2.9.0'\n\n}
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/app/build.gradle b/app/build.gradle
--- a/app/build.gradle	(revision 5205d2535d26021f98334bd1036174b1fe12aab5)
+++ b/app/build.gradle	(date 1654413057305)
@@ -28,7 +28,7 @@
             abiFilters "armeabi-v7a", "arm64-v8a", "x86", "x86_64"
         }
         python{
-            buildPython "C:\\Users\\sy\\AppData\\Local\\Programs\\Python\\Python37\\python.exe"
+            buildPython "/usr/bin/python3"
         }
         python{
             pip{
@@ -45,6 +45,11 @@
             proguardFiles getDefaultProguardFile('proguard-android-optimize.txt')
         }
     }
+    sourceSets{
+        main{
+            jniLibs.srcDirs = ['libs']
+        }
+    }
     compileOptions {
         sourceCompatibility JavaVersion.VERSION_1_8
         targetCompatibility JavaVersion.VERSION_1_8
@@ -52,9 +57,11 @@
     aaptOptions {
         noCompress "tflite"
     }
+    ndkVersion '22.1.7171670'
 }
 
 dependencies {
+    implementation fileTree(dir: 'libs', include: ['*.jar'])
     implementation 'androidx.appcompat:appcompat:1.2.0'
     implementation 'androidx.constraintlayout:constraintlayout:2.0.4'
     implementation files('libs\\TarsosDSP-Android-latest.jar')
@@ -71,5 +78,6 @@
     implementation('org.tensorflow:tensorflow-lite-support:0.0.0-nightly') { changing = true }
     implementation('com.alibaba:fastjson:1.1.72.android')
     implementation 'com.google.code.gson:gson:2.9.0'
+    implementation project(path: ':recorderlib')
 
 }
\ No newline at end of file
Index: .idea/vcs.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project version=\"4\">\n  <component name=\"VcsDirectoryMappings\">\n    <mapping directory=\"$PROJECT_DIR$\" vcs=\"Git\" />\n  </component>\n</project>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/vcs.xml b/.idea/vcs.xml
--- a/.idea/vcs.xml	(revision 5205d2535d26021f98334bd1036174b1fe12aab5)
+++ b/.idea/vcs.xml	(date 1654413057306)
@@ -1,6 +1,6 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <project version="4">
   <component name="VcsDirectoryMappings">
-    <mapping directory="$PROJECT_DIR$" vcs="Git" />
+    <mapping directory="" vcs="Git" />
   </component>
 </project>
\ No newline at end of file
Index: .idea/misc.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project version=\"4\">\n  <component name=\"ProjectRootManager\" version=\"2\" languageLevel=\"JDK_1_8\" project-jdk-name=\"1.8\" project-jdk-type=\"JavaSDK\">\n    <output url=\"file://$PROJECT_DIR$/build/classes\" />\n  </component>\n  <component name=\"ProjectType\">\n    <option name=\"id\" value=\"Android\" />\n  </component>\n</project>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/misc.xml b/.idea/misc.xml
--- a/.idea/misc.xml	(revision 5205d2535d26021f98334bd1036174b1fe12aab5)
+++ b/.idea/misc.xml	(date 1654413057310)
@@ -1,6 +1,6 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <project version="4">
-  <component name="ProjectRootManager" version="2" languageLevel="JDK_1_8" project-jdk-name="1.8" project-jdk-type="JavaSDK">
+  <component name="ProjectRootManager" version="2" languageLevel="JDK_1_8" default="true" project-jdk-name="1.8" project-jdk-type="JavaSDK">
     <output url="file://$PROJECT_DIR$/build/classes" />
   </component>
   <component name="ProjectType">
Index: app/src/main/java/org/pytorch/demo/speechrecognition/iflytek/SearchOneFeature.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>package org.pytorch.demo.speechrecognition.iflytek;\n\n\nimport com.alibaba.fastjson.JSON;\nimport com.alibaba.fastjson.JSONObject;\nimport com.google.gson.Gson;\n\nimport javax.crypto.Mac;\nimport javax.crypto.spec.SecretKeySpec;\nimport java.io.*;\nimport java.net.HttpURLConnection;\nimport java.net.URL;\nimport java.net.URLConnection;\nimport java.net.URLEncoder;\nimport java.nio.charset.Charset;\nimport java.text.SimpleDateFormat;\nimport java.util.Base64;\nimport java.util.Date;\nimport java.util.Locale;\nimport java.util.TimeZone;\n\n/**\n * 声纹识别1:1\n */\npublic class SearchOneFeature {\n    private String requestUrl;\n    private String APPID;\n    private String apiSecret;\n    private String apiKey;\n    private String GroupID=\"\";\n    private String FeatureID=\"\";\n    //音频存放位置\n    private static String AUDIO_PATH;\n\n    //解析Json\n    private static Gson json = new Gson();\n\n    //构造函数,为成员变量赋值\n    public SearchOneFeature(String requestUrl,String APPID,String apiSecret,String apiKey,String GroupID,String FeatureID,String AUDIO_PATH){\n        this.requestUrl=requestUrl;\n        this.APPID=APPID;\n        this.apiSecret=apiSecret;\n        this.apiKey=apiKey;\n        this.AUDIO_PATH=AUDIO_PATH;\n        this.GroupID=GroupID;\n        this.FeatureID=FeatureID;\n    }\n\n    //提供给主函数调用的方法\n    public static void doSearchOneFeature(String requestUrl,String APPID,String apiSecret,String apiKey,String GroupID,String FeatureID,String AUDIO_PATH) {\n        SearchOneFeature searchOneFeature = new SearchOneFeature(requestUrl, APPID, apiSecret, apiKey,GroupID,FeatureID, AUDIO_PATH);\n        try {\n            String resp = searchOneFeature.doRequest();\n            System.out.println(\"resp=>\" + resp);\n            JsonParse myJsonParse = json.fromJson(resp, JsonParse.class);\n            String textBase64Decode=new String(Base64.getDecoder().decode(myJsonParse.payload.searchScoreFeaRes.text), \"UTF-8\");\n            JSONObject jsonObject = JSON.parseObject(textBase64Decode);\n            System.out.println(\"text字段Base64解码后=>\"+jsonObject);\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n    /**\n     * 请求主方法\n     *\n     * @return 返回服务结果\n     * @throws Exception 异常\n     */\n    public String doRequest() throws Exception {\n        URL realUrl = new URL(buildRequetUrl());\n        URLConnection connection = realUrl.openConnection();\n        HttpURLConnection httpURLConnection = (HttpURLConnection) connection;\n        httpURLConnection.setDoInput(true);\n        httpURLConnection.setDoOutput(true);\n        httpURLConnection.setRequestMethod(\"POST\");\n        httpURLConnection.setRequestProperty(\"Content-type\", \"application/json\");\n\n        OutputStream out = httpURLConnection.getOutputStream();\n        String params = buildParam();\n        System.out.println(\"params=>\" + params);\n        out.write(params.getBytes());\n        out.flush();\n        InputStream is = null;\n        try {\n            is = httpURLConnection.getInputStream();\n        } catch (Exception e) {\n            is = httpURLConnection.getErrorStream();\n            throw new Exception(\"make request error:\" + \"code is \" + httpURLConnection.getResponseMessage() + readAllBytes(is));\n        }\n        return readAllBytes(is);\n    }\n\n    /**\n     * 处理请求URL\n     * 封装鉴权参数等\n     *\n     * @return 处理后的URL\n     */\n    public String buildRequetUrl() {\n        URL url = null;\n        // 替换调schema前缀 ，原因是URL库不支持解析包含ws,wss schema的url\n        String httpRequestUrl = requestUrl.replace(\"ws://\", \"http://\").replace(\"wss://\", \"https://\");\n        try {\n            url = new URL(httpRequestUrl);\n            //获取当前日期并格式化\n            SimpleDateFormat format = new SimpleDateFormat(\"EEE, dd MMM yyyy HH:mm:ss z\", Locale.US);\n            format.setTimeZone(TimeZone.getTimeZone(\"GMT\"));\n            String date = format.format(new Date());\n\n            String host = url.getHost();\n            if (url.getPort() != 80 && url.getPort() != 443) {\n                host = host + \":\" + String.valueOf(url.getPort());\n            }\n            StringBuilder builder = new StringBuilder(\"host: \").append(host).append(\"\\n\").//\n                    append(\"date: \").append(date).append(\"\\n\").//\n                    append(\"POST \").append(url.getPath()).append(\" HTTP/1.1\");\n            Charset charset = Charset.forName(\"UTF-8\");\n            Mac mac = Mac.getInstance(\"hmacsha256\");\n            SecretKeySpec spec = new SecretKeySpec(apiSecret.getBytes(charset), \"hmacsha256\");\n            mac.init(spec);\n            byte[] hexDigits = mac.doFinal(builder.toString().getBytes(charset));\n            String sha = Base64.getEncoder().encodeToString(hexDigits);\n\n            String authorization = String.format(\"api_key=\\\"%s\\\", algorithm=\\\"%s\\\", headers=\\\"%s\\\", signature=\\\"%s\\\"\", apiKey, \"hmac-sha256\", \"host date request-line\", sha);\n            String authBase = Base64.getEncoder().encodeToString(authorization.getBytes(charset));\n            return String.format(\"%s?authorization=%s&host=%s&date=%s\", requestUrl, URLEncoder.encode(authBase), URLEncoder.encode(host), URLEncoder.encode(date));\n\n        } catch (Exception e) {\n            throw new RuntimeException(\"assemble requestUrl error:\" + e.getMessage());\n        }\n    }\n\n    /**\n     * 组装请求参数\n     * 直接使用示例参数，\n     * 替换部分值\n     *\n     * @return 参数字符串\n     */\n    private String buildParam() throws IOException {\n        String param = \"{\" +\n                \"    \\\"header\\\": {\" +\n                \"        \\\"app_id\\\": \\\"\" + APPID + \"\\\",\" +\n                \"        \\\"status\\\": 3\" +\n                \"    },\" +\n                \"    \\\"parameter\\\": {\" +\n                \"        \\\"s782b4996\\\": {\" +\n                \"            \\\"func\\\": \\\"searchScoreFea\\\",\" +\n                //这里填上所需要的groupId\n                \"            \\\"groupId\\\": \\\"iFLYTEK_examples_groupId\\\",\" +\n                //这里填上所需要的featureId\n                \"            \\\"dstFeatureId\\\": \\\"iFLYTEK_examples_featureId\\\",\" +\n                \"            \\\"searchScoreFeaRes\\\": {\" +\n                \"                \\\"encoding\\\": \\\"utf8\\\",\" +\n                \"                \\\"compress\\\": \\\"raw\\\",\" +\n                \"                \\\"format\\\": \\\"json\\\"\" +\n                \"            }\" +\n                \"        }\" +\n                \"    },\" +\n                \"\\\"payload\\\":{\" +\n                \"    \\\"resource\\\": {\" +\n                //这里根据不同的音频编码填写不同的编码格式\n                \"        \\\"encoding\\\": \\\"lame\\\",\" +\n                \"        \\\"sample_rate\\\": 16000,\" +\n                \"        \\\"channels\\\": 1,\" +\n                \"        \\\"bit_depth\\\": 16,\" +\n                \"        \\\"status\\\": \" + 3 + \",\" +\n                \"        \\\"audio\\\": \\\"\"+Base64.getEncoder().encodeToString(read(AUDIO_PATH))+\"\\\"\"+\n                \"    }}\" +\n                \"}\";\n        return param;\n    }\n\n    /**\n     * 读取流数据\n     *\n     * @param is 流\n     * @return 字符串\n     * @throws IOException 异常\n     */\n    private String readAllBytes(InputStream is) throws IOException {\n        byte[] b = new byte[1024];\n        StringBuilder sb = new StringBuilder();\n        int len = 0;\n        while ((len = is.read(b)) != -1){\n            sb.append(new String(b, 0, len, \"utf-8\"));\n        }\n        return sb.toString();\n    }\n\n    public static byte[] read(String filePath) throws IOException {\n        InputStream in = new FileInputStream(filePath);\n        byte[] data = inputStream2ByteArray(in);\n        in.close();\n        return data;\n    }\n    private static byte[] inputStream2ByteArray(InputStream in) throws IOException {\n        ByteArrayOutputStream out = new ByteArrayOutputStream();\n        byte[] buffer = new byte[1024 * 4];\n        int n = 0;\n        while ((n = in.read(buffer)) != -1) {\n            out.write(buffer, 0, n);\n        }\n        return out.toByteArray();\n    }\n    //Json解析\n    class JsonParse {\n        public Header header;\n        public Payload payload;\n    }\n    class Header{\n        public int code;\n        public String message;\n        public String sid;\n        public int status;\n    }\n    class Payload{\n        //根据model的取值不同,名字有所变动。\n        public SearchScoreFeaRes searchScoreFeaRes;\n    }\n    class SearchScoreFeaRes{\n        public String compress;\n        public String encoding;\n        public String format;\n        public String text;\n    }\n}\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/app/src/main/java/org/pytorch/demo/speechrecognition/iflytek/SearchOneFeature.java b/app/src/main/java/org/pytorch/demo/speechrecognition/iflytek/SearchOneFeature.java
--- a/app/src/main/java/org/pytorch/demo/speechrecognition/iflytek/SearchOneFeature.java	(revision 5205d2535d26021f98334bd1036174b1fe12aab5)
+++ b/app/src/main/java/org/pytorch/demo/speechrecognition/iflytek/SearchOneFeature.java	(date 1654413057312)
@@ -147,9 +147,9 @@
                 "        \"s782b4996\": {" +
                 "            \"func\": \"searchScoreFea\"," +
                 //这里填上所需要的groupId
-                "            \"groupId\": \"iFLYTEK_examples_groupId\"," +
+                "            \"groupId\": \""+GroupID+"\"," +
                 //这里填上所需要的featureId
-                "            \"dstFeatureId\": \"iFLYTEK_examples_featureId\"," +
+                "            \"dstFeatureId\": \""+FeatureID+"\"," +
                 "            \"searchScoreFeaRes\": {" +
                 "                \"encoding\": \"utf8\"," +
                 "                \"compress\": \"raw\"," +
Index: app/src/main/java/org/pytorch/demo/speechrecognition/VoicePrint.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>package org.pytorch.demo.speechrecognition;\n\nimport android.os.Environment;\n\nimport org.pytorch.demo.speechrecognition.iflytek.CreateFeature;\nimport org.pytorch.demo.speechrecognition.iflytek.CreateGroup;\nimport org.pytorch.demo.speechrecognition.iflytek.QueryFeatureList;\nimport org.pytorch.demo.speechrecognition.iflytek.SearchOneFeature;\n\nimport java.io.File;\nimport java.util.Random;\n\npublic class VoicePrint {\n    private static String requestUrl = \"https://api.xf-yun.com/v1/private/s782b4996\";\n\n    //控制台获取以下信息\n    private static String APPID = \"3f0f566d\";\n    private static String apiSecret = \"NjljY2Y2OTU0NTVlZTFhMDE5YTU0NWRi\";\n    private static String apiKey = \"e860d30ff1c5f572c07731f715464b32\";\n\n\n    private String GroupID=\"\";\n    private String FeatureID=\"\";\n    VoicePrint(){\n        Random r = new Random();\n        GroupID=String.valueOf(\"test_2022_6_2\"+r.nextInt(10000));\n        FeatureID=String.valueOf(\"test_2022_6_2\"+r.nextInt(10000));\n    }\n\n    //音频存放位置(比对功能请注意更换音频)\n    private static String AUDIO_PATH = (new File(Environment.getExternalStoragePublicDirectory(Environment.DIRECTORY_DOWNLOADS),\n                \"/myEmovo/record/record.wav\")).getAbsolutePath();//Environment.DIRECTORY_DOWNLOADS+\"/myEmovo/record/record.wav\";//\"audioExample/讯飞开放平台.mp3\";\n\n    public void vpCreateGroup(){\n        CreateGroup.doCreateGroup(requestUrl,APPID,apiSecret,apiKey,GroupID,FeatureID);\n    }\n\n    public void vpCreateFeature(){\n        CreateFeature.doCreateFeature(requestUrl,APPID,apiSecret,apiKey,GroupID,FeatureID,AUDIO_PATH);\n    }\n\n    public void vpQueryFeatureList(){\n        QueryFeatureList.doQueryFeatureList(requestUrl,APPID,apiSecret,apiKey);\n    }\n\n    public void vpSearchOneFeature(){\n        SearchOneFeature.doSearchOneFeature(requestUrl,APPID,apiSecret,apiKey,GroupID,FeatureID,AUDIO_PATH);\n    }\n\n    \n\n\n    public void main(String[] args) {\n        /**1.创建声纹特征库*/\n        CreateGroup.doCreateGroup(requestUrl,APPID,apiSecret,apiKey,GroupID,FeatureID);\n        /**2.添加音频特征*/\n        //CreateFeature.doCreateFeature(requestUrl,APPID,apiSecret,apiKey,AUDIO_PATH);\n        /**3.查询特征列表*/\n        //QueryFeatureList.doQueryFeatureList(requestUrl,APPID,apiSecret,apiKey);\n        /**4.特征比对1:1*/\n        //SearchOneFeature.doSearchOneFeature(requestUrl,APPID,apiSecret,apiKey,AUDIO_PATH);\n        /**5.特征比对1:N*/\n        //SearchFeature.doSearchFeature(requestUrl,APPID,apiSecret,apiKey,AUDIO_PATH);\n        /**6.更新音频特征*/\n        //UpdateFeature.doUpdateFeature(requestUrl,APPID,apiSecret,apiKey,AUDIO_PATH);\n        /**7.删除指定特征*/\n        //DeleteFeature.doDeleteFeature(requestUrl,APPID,apiSecret,apiKey);\n        /**8.删除声纹特征库*/\n        //DeleteGroup.doDeleteGroup(requestUrl,APPID,apiSecret,apiKey);\n    }\n}\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/app/src/main/java/org/pytorch/demo/speechrecognition/VoicePrint.java b/app/src/main/java/org/pytorch/demo/speechrecognition/VoicePrint.java
--- a/app/src/main/java/org/pytorch/demo/speechrecognition/VoicePrint.java	(revision 5205d2535d26021f98334bd1036174b1fe12aab5)
+++ b/app/src/main/java/org/pytorch/demo/speechrecognition/VoicePrint.java	(date 1654413057314)
@@ -35,16 +35,16 @@
         CreateGroup.doCreateGroup(requestUrl,APPID,apiSecret,apiKey,GroupID,FeatureID);
     }
 
-    public void vpCreateFeature(){
-        CreateFeature.doCreateFeature(requestUrl,APPID,apiSecret,apiKey,GroupID,FeatureID,AUDIO_PATH);
+    public void vpCreateFeature(String audio_path){
+        CreateFeature.doCreateFeature(requestUrl,APPID,apiSecret,apiKey,GroupID,FeatureID,audio_path);
     }
 
     public void vpQueryFeatureList(){
         QueryFeatureList.doQueryFeatureList(requestUrl,APPID,apiSecret,apiKey);
     }
 
-    public void vpSearchOneFeature(){
-        SearchOneFeature.doSearchOneFeature(requestUrl,APPID,apiSecret,apiKey,GroupID,FeatureID,AUDIO_PATH);
+    public void vpSearchOneFeature(String audio_path){
+        SearchOneFeature.doSearchOneFeature(requestUrl,APPID,apiSecret,apiKey,GroupID,FeatureID,audio_path);
     }
 
     
