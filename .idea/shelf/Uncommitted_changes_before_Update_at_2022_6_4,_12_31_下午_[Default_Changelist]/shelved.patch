Index: app/src/main/java/org/pytorch/demo/speechrecognition/MainActivity.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>package org.pytorch.demo.speechrecognition;\n\nimport android.Manifest;\nimport android.accessibilityservice.AccessibilityService;\nimport android.animation.ValueAnimator;\nimport android.annotation.SuppressLint;\nimport android.app.Activity;\nimport android.content.Context;\nimport android.content.Intent;\nimport android.content.pm.PackageInfo;\nimport android.content.pm.PackageManager;\nimport android.graphics.PixelFormat;\nimport android.graphics.drawable.Drawable;\nimport android.hardware.Sensor;\nimport android.hardware.SensorEvent;\nimport android.hardware.SensorEventListener;\nimport android.hardware.SensorManager;\nimport android.media.AudioFormat;\nimport android.media.AudioManager;\nimport android.media.AudioRecord;\nimport android.media.MediaRecorder;\nimport android.media.MediaScannerConnection;\nimport android.media.SoundPool;\nimport android.net.Uri;\nimport android.os.Build;\nimport android.os.Bundle;\nimport android.os.Environment;\nimport android.os.Handler;\nimport android.os.HandlerThread;\nimport android.os.Looper;\nimport android.os.ParcelFileDescriptor;\nimport android.os.VibrationEffect;\nimport android.os.Vibrator;\nimport android.provider.Settings;\nimport android.speech.RecognitionListener;\nimport android.speech.RecognizerIntent;\nimport android.speech.SpeechRecognizer;\nimport android.text.TextUtils;\nimport android.util.Log;\nimport android.view.Gravity;\nimport android.view.LayoutInflater;\nimport android.view.View;\nimport android.view.WindowManager;\nimport android.view.accessibility.AccessibilityEvent;\nimport android.view.accessibility.AccessibilityNodeInfo;\nimport android.widget.Button;\nimport android.widget.FrameLayout;\nimport android.widget.ImageButton;\nimport android.widget.ImageView;\nimport android.widget.ProgressBar;\nimport android.widget.TextView;\nimport android.widget.Toast;\n\nimport androidx.appcompat.app.AppCompatActivity;\nimport androidx.core.app.ActivityCompat;\nimport androidx.core.content.ContextCompat;\n\n\nimport org.pytorch.IValue;\nimport org.pytorch.Module;\nimport org.pytorch.Tensor;\n\nimport java.io.BufferedWriter;\nimport java.io.File;\nimport java.io.FileInputStream;\nimport java.io.FileNotFoundException;\nimport java.io.FileOutputStream;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.OutputStream;\nimport java.io.OutputStreamWriter;\nimport java.nio.FloatBuffer;\nimport java.nio.MappedByteBuffer;\nimport java.text.BreakIterator;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Locale;\nimport java.util.Timer;\nimport java.util.TimerTask;\n\n\nimport org.pytorch.LiteModuleLoader;\n\nimport com.chaquo.python.Python;\n//import com.chaquo.python.android.AndroidPlatform;\nimport com.chaquo.python.PyObject;\n//import com.chaquo.python.Kwarg;\n\nimport org.tensorflow.lite.Interpreter;\nimport org.tensorflow.lite.support.common.FileUtil;\n\n\n\n\npublic class MainActivity extends AppCompatActivity implements Runnable {\n    private static final String TAG = MainActivity.class.getName();\n\n    private Module mModuleEncoder;\n    private TextView mtvEmoState;\n    public TextView mtvTest;\n    private ImageButton mButton;\n    private ImageButton mImgbExtractFeature;\n    private ImageButton mImgbCheckFeature;\n    private ImageView mImgvEmoState;\n    private ProgressBar mprobarEmoInference;\n    private boolean mButtonisPlay=false;\n\n\n    private int EmoState=EMO_NEUTRAL;\n    private float EmoInference=0;\n\n    private final static int EMO_NEUTRAL=1;\n    private final static int EMO_ANGER=2;\n    private final static int REQUEST_RECORD_AUDIO = 13;\n    private final static int AUDIO_LEN_IN_SECOND = 5;\n    private final static int SAMPLE_RATE = 16000;//22050;//16000;\n    private final static int RECORDING_LENGTH = SAMPLE_RATE * AUDIO_LEN_IN_SECOND;\n\n    private final static int HOP_LENGTH=512;\n    private final static int FRAME_LENGTH=2048;\n\n    private final static String LOG_TAG = MainActivity.class.getSimpleName();\n\n    private int mStart = 1;\n    private HandlerThread mTimerThread;\n    private Handler mTimerHandler;\n\n\n    private final static int MIC_ON=1;\n    private final static int MIC_OFF=2;\n\n    private final static int Announce_Mode=0;//最终模式，同时包括倒置开麦和拍拍开麦\n    private final static int GreatMeeting_Mode=1;//倒置麦克风开麦\n    private final static int HandFree_mode=2;//拍拍开麦\n\n    private SensorManager sm;\n    private Sensor mSensorOrientation;\n    private SensListener sensListener=new SensListener();\n\n    private Vibrator vibrator;\n    private SensorManager sensorManager;\n    private SpeechRecognizer speechRecognizer;\n    private int samplingPeriod = 10000;\n\n    private static int seqLength = 60;\n    private float[][][] input = new float[1][seqLength][6];\n\n    private long[] lastTime = new long[2];\n    private long firstTapTime = 0;\n    private int skipNum = seqLength;\n    private boolean secondFlag = false;\n\n    private MappedByteBuffer firstModel;\n    private MappedByteBuffer secondModel;\n    private Interpreter firstInterpreter;\n    private Interpreter secondInterpreter;\n    private final Interpreter.Options tfliteOptions = new Interpreter.Options();\n    private float[][] output = new float[1][3];\n\n    private List<Long> lastRecognizedTime = new ArrayList<>();\n\n    private int MicInstantMode=HandFree_mode;\n    private int MicState=MIC_OFF;\n\n    private TextView mtvMicInstantMode;\n\n    private SoundPool soundPool;\n\n    Intent speechRecognizerIntent;\n    private HandlerThread TimerThread;\n    private Handler TimerHandler;\n    private int Timer_time=0;\n\n    Thread SensorService_thread;\n    Thread FloatingWindow_thread;\n    Thread SpeechDetector_thread;\n    Thread VoicePrint_thread;\n    Thread MicOnTimer_thread;\n\n    private HandlerThread MicOnTimerThread;\n    private Handler MicOnTimerHandler;\n    private int MicOnTimer_time=0;\n\n    //AudioManager audiomanage = (AudioManager)getApplicationContext().getSystemService(Context.AUDIO_SERVICE);\n\n    Handler FloatingWindow_handler=new Handler(Looper.getMainLooper());\n\n    private int VoicePrintFlag=0;\n    private static int VoicePrint_CREATEFEATURE=0;\n    private static int VoicePrint_CHECKFEATURE=1;\n    private static int VoicePrint_CHECKGROUP=2;\n\n    private VoicePrint voicePrint=new VoicePrint();\n\n\n\n    //private TMAccessibilityService TMcontrol=new TMAccessibilityService();\n\n\n\n    private Runnable mRunnable = new Runnable() {\n        @Override\n        public void run() {\n            mTimerHandler.postDelayed(mRunnable, 1000);\n            Log.i(TAG,\"recorder timer\");\n\n            MainActivity.this.runOnUiThread(\n                    () -> {\n                        mtvTest.setText(String.format(\"Listening - %ds left\", AUDIO_LEN_IN_SECOND - mStart));\n                        mStart += 1;\n                    });\n        }\n    };\n\n    private Runnable SensorService_runnable =new Runnable() {\n        @Override\n        public void run() {\n            initSensor();\n        }\n    };\n\n\n    Runnable FloatingWindow_runnable =new Runnable() {\n        @Override\n        public void run(){\n            //TmAccessibilityService.initFloatingWindow();\n            try {\n                startService(new Intent(MainActivity.this, FloatWindow.class));\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n\n\n        }\n    };\n\n    Runnable MicOnTimer_runnable=new Runnable() {\n        @Override\n        public void run() {\n            MicOnTimerHandler.postDelayed(MicOnTimer_runnable, 1000);\n            Timer_time+=1;\n            Log.e(TAG, \"MicOnTimer running\");\n            if(Timer_time>5){\n                stopMicOnTimer();\n                Log.i(TAG,\"MicOnTimer:\"+Timer_time);\n                //speechRecognizer.stopListening();\n            }\n        }\n    };\n    protected void stopMicOnTimer() {\n        MicOnTimerThread.quitSafely();\n        try {\n            MicOnTimerThread.join();\n            MicOnTimerThread = null;\n            MicOnTimerHandler = null;\n            MicOnTimer_time = 0;\n        } catch (InterruptedException e) {\n            Log.e(TAG, \"Error on stopping background thread\", e);\n        }\n    }\n    private void MicOnstartTimer(){\n        //Thread thread = new Thread(MainActivity.this);\n        //thread.start();\n        MicOnTimerThread = new HandlerThread(\"ClockTimer\");\n        MicOnTimerThread.start();\n        MicOnTimerHandler = new Handler(MicOnTimerThread.getLooper());\n        MicOnTimerHandler.postDelayed(MicOnTimer_runnable, 1000);\n        Log.e(TAG, \"startMicOnTimer\");\n    }\n\n\n    protected void stopTimerThread() {\n        mTimerThread.quitSafely();\n        try {\n            mTimerThread.join();\n            mTimerThread = null;\n            mTimerHandler = null;\n            mStart = 1;\n        } catch (InterruptedException e) {\n            Log.e(TAG, \"Error on stopping background thread\", e);\n        }\n    }\n\n\n    @SuppressLint(\"WrongViewCast\")\n    @Override\n    protected void onCreate(Bundle savedInstanceState) {\n        super.onCreate(savedInstanceState);\n        setContentView(R.layout.activity_main);\n        getSupportActionBar().hide();\n        mButton = findViewById(R.id.imgbtnSorP);\n        mButton.setImageResource(R.drawable.icon2);\n        mImgvEmoState=findViewById(R.id.imgvEmoState);\n        mImgbExtractFeature=findViewById(R.id.imgbtnExtractFeature);\n        mImgbCheckFeature=findViewById(R.id.imgbtnCheckFeature);\n        mtvEmoState = findViewById(R.id.tvState);\n        mtvTest=findViewById(R.id.tvTest);\n        mprobarEmoInference=findViewById(R.id.probarEmoInference);\n\n        mtvMicInstantMode = findViewById(R.id.tvMicInstantMode);\n        mprobarEmoInference.setProgress(1);\n\n        //initVoicePrint();\n\n        mButton.setOnClickListener(new View.OnClickListener() {\n            public void onClick(View v) {\n//                //mButton.setText(String.format(\"Listening - %ds left\", AUDIO_LEN_IN_SECOND));\n//                mButton.setEnabled(false);\n//\n//                Thread thread = new Thread(MainActivity.this);\n//                thread.start();\n//\n//                mTimerThread = new HandlerThread(\"Timer\");\n//                mTimerThread.start();\n//                mTimerHandler = new Handler(mTimerThread.getLooper());\n//                mTimerHandler.postDelayed(mRunnable, 1000);\n//                if(mButtonisPlay){\n//                    ((ImageButton)v).setImageResource(R.drawable.icon2);\n//                    mtvTest.setText(\"Stop Run\");\n//                }\n//                else{\n//                    ((ImageButton)v).setImageResource(R.drawable.icon1);\n//                    mtvTest.setText(\"Recording\");\n//                }\n//                mButtonisPlay = !mButtonisPlay;\n                if (MicInstantMode==Announce_Mode){\n                    MicInstantMode=GreatMeeting_Mode;\n                    mtvMicInstantMode.setText(\"       GreatMeeting\");\n                }\n                else if(MicInstantMode==GreatMeeting_Mode){\n                    MicInstantMode=HandFree_mode;\n                    mtvMicInstantMode.setText(\"       HandFree\");\n                }\n                else if(MicInstantMode==HandFree_mode){\n                    MicInstantMode=Announce_Mode;\n                    mtvMicInstantMode.setText(\"   AnnounceMode\");\n                }\n                mButtonisPlay = !mButtonisPlay;\n\n            }\n        });\n//        mImgbExtractFeature.setOnClickListener(new View.OnClickListener() {\n//            public void onClick(View v) {\n//                startVoicePrint(VoicePrint_CREATEFEATURE);\n//                mButtonisPlay = !mButtonisPlay;\n//\n//            }\n//        });\n//        mImgbCheckFeature.setOnClickListener(new View.OnClickListener() {\n//            public void onClick(View v) {\n//                startVoicePrint(VoicePrint_CHECKFEATURE);\n//                mButtonisPlay = !mButtonisPlay;\n//            }\n//        });\n        //requestMicrophonePermission();\n\n        //initSensor();\n        //initSpeechDetector();\n        Log.i(TAG, \"Main::oncreate done \");\n\n        Utils.writeTxtToFile(\"Main::oncreate done \",\"/logs\",\"log.txt\");\n        startTimer();\n\n        //initAccessibility(this.getApplicationContext(),\"TMAccessibilityService\");\n    }\n\n    @Override\n    protected void onResume() {\n        super.onResume();\n        Utils.writeTxtToFile(\"onResume \",\"/logs\",\"log.txt\");\n        if (!TmAccessibilityService.isStart()) {\n            try {\n                this.startActivity(new Intent(Settings.ACTION_ACCESSIBILITY_SETTINGS));\n            } catch (Exception e) {\n                this.startActivity(new Intent(Settings.ACTION_SETTINGS));\n                e.printStackTrace();\n            }\n        }\n        else {\n            InitafterTmConnected();\n        }\n    }\n    public void InitafterTmConnected(){\n        if(SensorService_thread==null) {\n            requestStoragePermission();\n            initSoudpool();\n            SensorService_thread = new Thread(SensorService_runnable);\n            SensorService_thread.start();\n        }\n        if(FloatingWindow_thread==null){\n            if(Settings.canDrawOverlays(this)){\n                Log.i(TAG,\"start floating window...\");\n                FloatingWindow_thread=new Thread(FloatingWindow_runnable);\n                FloatingWindow_thread.start();\n                //SpeechDetector_thread=new Thread(SpeechDetector_runnable);\n                //SpeechDetector_thread.start();\n                //initSpeechDetector();\n                //SpeechDetect();\n                //System.out.println(FloatWindow.isStart());\n                startApp(\"com.tencent.wemeet.app\");\n                Utils.writeTxtToFile(\"com.tencent.wemeet.app1\",\"/logs\",\"log.txt\");\n\n\n//                    TmAccessibilityService.mService.startFloatingWindow();\n            }\n            else {\n                requestFloatingWindow();\n            }\n        }\n    }\n\n    @SuppressLint(\"WrongConstant\")\n    private void startApp(String packname){\n        PackageManager packageManager = getPackageManager();\n        if (checkPackInfo(packname)) {\n            Intent intent = packageManager.getLaunchIntentForPackage(packname);\n            startActivity(intent);\n        } else {\n            Toast.makeText(MainActivity.this, \"没有安装\" + packname, 1).show();\n        }\n    }\n    private boolean checkPackInfo(String packname) {\n        PackageInfo packageInfo = null;\n        try {\n            packageInfo = getPackageManager().getPackageInfo(packname, 0);\n        } catch (PackageManager.NameNotFoundException e) {\n            e.printStackTrace();\n        }\n        return packageInfo != null;\n    }\n\n\n    private void requestFloatingWindow(){\n        Toast.makeText(this, \"Please permit float window...\", Toast.LENGTH_SHORT);\n        Intent intent = new Intent();\n        intent.setAction(Settings.ACTION_MANAGE_OVERLAY_PERMISSION);\n        intent.setData(Uri.parse(\"package:\" + getPackageName()));\n        startActivityForResult(intent, 0);\n    }\n\n\n    private void initSoudpool(){\n        soundPool= new SoundPool.Builder()\n                .setMaxStreams(10)\n                .build();\n        soundPool.load(this,R.raw.sound_micon,1);\n        soundPool.load(this,R.raw.sound_micoff,2);\n    }\n\n    public void initSensor(){\n        //倒置控制\n        sm = (SensorManager) getSystemService(SENSOR_SERVICE);\n        // 获取方向传感器\n        mSensorOrientation = sm.getDefaultSensor(Sensor.TYPE_MAGNETIC_FIELD);\n        //注册数值变化监听器\n        sm.registerListener(sensListener, mSensorOrientation,SensorManager.SENSOR_DELAY_UI);\n\n        //PatPat控制\n        vibrator = (Vibrator)getSystemService(Context.VIBRATOR_SERVICE);\n        sensorManager = (SensorManager) getSystemService(Context.SENSOR_SERVICE);\n        Sensor gyroSensor = sensorManager.getDefaultSensor(Sensor.TYPE_GYROSCOPE);\n        sensorManager.registerListener(gyroListener, gyroSensor, samplingPeriod);\n        Sensor linearAccSensor = sensorManager.getDefaultSensor(Sensor.TYPE_LINEAR_ACCELERATION);\n        sensorManager.registerListener(linearAccListener, linearAccSensor, samplingPeriod);\n\n        tfliteOptions.setNumThreads(4);\n        try {\n            firstModel = FileUtil.loadMappedFile(getApplicationContext(), String.format(\"first.tflite\"));\n            //firstModel = FileUtil.loadMappedFile(assetFilePath(getApplicationContext(), \"Model2.ptl\"));\n            firstInterpreter = new Interpreter(firstModel, tfliteOptions);\n        } catch (IOException e) {\n            Log.e(\"Load Model\", \"model load fail\");\n            e.printStackTrace();\n            System.out.println(\"first model load fail\");\n        }\n        try {\n            secondModel = FileUtil.loadMappedFile(getApplicationContext(), String.format(\"second.tflite\"));\n            secondInterpreter = new Interpreter(secondModel, tfliteOptions);\n        } catch (IOException e) {\n            Log.e(\"Load Model\", \"model load fail\");\n            e.printStackTrace();\n            System.out.println(\"second model load fail\");\n        }\n    }\n\n    private class SensListener extends AppCompatActivity implements SensorEventListener {\n        private float Mx,My,Mz;\n\n        // 传感器数值变化会调用此方法\n\n        @Override\n        public void onSensorChanged( SensorEvent event) {\n            Mx=(float) (Math.round(event.values[0] * 100)) / 100;\n            My=(float) (Math.round(event.values[1] * 100)) / 100;//手机纵向地磁加速度\n            Mz=(float) (Math.round(event.values[2] * 100)) / 100;\n\n            runOnUiThread(new Runnable() {\n                @Override\n                public void run() {\n                    mtvTest.setText(String.valueOf(Mx)+\"\\n\"+String.valueOf(My)+\"\\n\"+String.valueOf(Mz));\n                }\n\n            });\n            if(MicInstantMode==GreatMeeting_Mode || MicInstantMode==Announce_Mode){\n                CheckGesture();\n            }\n\n        }\n\n        private void CheckGesture(){\n            if (MicState==MIC_OFF && My>40 && Math.abs(My)>(Math.abs(Mx+Mz)*2)){\n                MicState=MIC_ON;\n                changeMicState();\n                soundPool.play(1,1, 1, 0, 0, 1);\n            }\n            else if(MicState==MIC_ON && My<-40 && Math.abs(My)>(Math.abs(Mx+Mz)*2)){\n                MicState=MIC_OFF;\n                changeMicState();\n                soundPool.play(2,1, 1, 0, 0, 1);\n            }\n\n        }\n\n        @Override\n        public void onAccuracyChanged(Sensor sensor, int accuracy) {\n        }\n\n    }\n\n    private void changeMicState(){\n        int res;\n        String MicHint=\"\";\n        startTimer();\n\n        if (MicState==MIC_ON) {\n            res = R.drawable.mic_on;\n            if (TmAccessibilityService.mService.CheckMicOn()==0) {\n                TmAccessibilityService.mService.ClickView(TmAccessibilityService.mService.vid_InMeeting_Mic);\n            }\n            TmAccessibilityService.mService.SetMicMute(false);\n            MicHint=\"Microphone ON!\";\n        }\n        else if(EmoState==MIC_OFF){\n            res=R.drawable.mic_off;\n            if (TmAccessibilityService.mService.CheckMicOn()==1) {\n                TmAccessibilityService.mService.ClickView(TmAccessibilityService.mService.vid_InMeeting_Mic);\n                //audiomanage.setMicrophoneMute(true);\n            }\n            MicHint=\"Microphone OFF!\";\n        }\n        else {\n            res=R.drawable.mic_off;\n            if (TmAccessibilityService.mService.CheckMicOn()==1) {\n                TmAccessibilityService.mService.ClickView(TmAccessibilityService.mService.vid_InMeeting_Mic);\n            }\n            TmAccessibilityService.mService.SetMicMute(true);\n            MicHint=\"Microphone OFF!\";\n        }\n        mImgvEmoState.setImageResource(res);\n        mtvEmoState.setText(MicHint);\n    }\n\n    private Runnable SpeechDetector_runnable =new Runnable() {\n        @Override\n        public void run() {\n            initSpeechDetector();\n        }\n    };\n\n    private void initSpeechDetector(){\n        speechRecognizer = SpeechRecognizer.createSpeechRecognizer(this);\n\n        speechRecognizerIntent = new Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH);\n        speechRecognizerIntent.putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL,RecognizerIntent.LANGUAGE_MODEL_FREE_FORM);\n        speechRecognizerIntent.putExtra(RecognizerIntent.EXTRA_LANGUAGE, Locale.getDefault());\n        speechRecognizer.setRecognitionListener(new RecognitionListener() {\n            @Override\n            public void onReadyForSpeech(Bundle bundle) {\n            }\n            @Override\n            public void onBeginningOfSpeech() {\n                System.out.println(\"start detecting...\");\n            }\n            @Override\n            public void onRmsChanged(float v) {\n            }\n            @Override\n            public void onBufferReceived(byte[] bytes) {\n            }\n\n            @Override\n            public void onEndOfSpeech() {\n            }\n            @Override\n            public void onError(int i) {\n            }\n\n            @Override\n            public void onResults(Bundle bundle) {\n                ArrayList<String> data = bundle.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION);\n                if (data.size()<1){\n                    Log.i(TAG,\"no speech detected!\");\n                }\n                else {\n                    for (int i = 0; i < data.size(); i++) {\n                        System.out.println(data.get(i));\n                    }\n                }\n            }\n\n            @Override\n            public void onPartialResults(Bundle bundle) {\n            }\n\n            @Override\n            public void onEvent(int i, Bundle bundle) {\n            }\n        });\n    }\n    private void SpeechDetect(){\n\n        speechRecognizer.startListening(speechRecognizerIntent);\n        startTimer();\n\n    }\n\n    private Runnable TimerRunnable = new Runnable() {\n        @Override\n        public void run() {\n            TimerHandler.postDelayed(TimerRunnable, 1000);\n            Timer_time+=1;\n            Log.e(TAG, \"Timer running\");\n            if(Timer_time>5){\n                stopTimer();\n                Log.i(TAG,\"Timer:\"+Timer_time);\n                //speechRecognizer.stopListening();\n            }\n        }\n    };\n    protected void stopTimer() {\n        TimerThread.quitSafely();\n        try {\n            TimerThread.join();\n            TimerThread = null;\n            TimerHandler = null;\n            speechRecognizer.stopListening();\n            Timer_time = 0;\n        } catch (InterruptedException e) {\n            Log.e(TAG, \"Error on stopping background thread\", e);\n        }\n    }\n    private void startTimer(){\n        //Thread thread = new Thread(MainActivity.this);\n        //thread.start();\n\n        TimerThread = new HandlerThread(\"ClockTimer\");\n        TimerThread.start();\n        TimerHandler = new Handler(TimerThread.getLooper());\n        TimerHandler.postDelayed(TimerRunnable, 1000);\n        Log.e(TAG, \"startTimer\");\n    }\n\n    private void initAccessibility(Context ct, String serviceClass){\n        boolean haspermisssion=false;\n        int ok = 0;\n        try {\n            ok = Settings.Secure.getInt(ct.getContentResolver(), Settings.Secure.ACCESSIBILITY_ENABLED);\n        } catch (Settings.SettingNotFoundException e) {\n        }\n\n        TextUtils.SimpleStringSplitter ms = new TextUtils.SimpleStringSplitter(':');\n        if (ok == 1) {\n            String settingValue = Settings.Secure.getString(ct.getContentResolver(), Settings.Secure.ENABLED_ACCESSIBILITY_SERVICES);\n            if (settingValue != null) {\n                ms.setString(settingValue);\n                while (ms.hasNext()) {\n                    String accessibilityService = ms.next();\n                    if (accessibilityService.contains(serviceClass)) {\n                        haspermisssion=true;\n                    }\n                }\n            }\n        }\n\n        if (!haspermisssion){\n            // jump to setting permission\n            Intent intent = new Intent(Settings.ACTION_ACCESSIBILITY_SETTINGS);\n            intent.addFlags(Intent.FLAG_ACTIVITY_NEW_TASK);\n            ct.startActivity(intent);\n        }\n    }\n\n    //control tencent meeting\n//    public static class TMAccessibilityService extends AccessibilityService{\n//        private final String TAG = MainActivity.class\n//                .getSimpleName();\n//        private final String packageName=\"com.tencent.wemeet.app:id/\";\n//\n//        @Override\n//        public void onAccessibilityEvent(AccessibilityEvent event) {\n//            Log.i(TAG, \"ACC::onAccessibilityEvent: \" + event.getEventType());\n//\n//            //TYPE_WINDOW_STATE_CHANGED == 32\n//            if (AccessibilityEvent.TYPE_WINDOW_STATE_CHANGED == event\n//                    .getEventType()) {\n//                AccessibilityNodeInfo nodeInfo = event.getSource();\n//                Log.i(TAG, \"ACC::onAccessibilityEvent: nodeInfo=\" + nodeInfo);\n//                if (nodeInfo == null) {\n//                    return;\n//                }\n//\n//                List<AccessibilityNodeInfo> list = nodeInfo\n//                        .findAccessibilityNodeInfosByViewId(packageName+\"i9\");\n//                for (AccessibilityNodeInfo node : list) {\n//                    Log.i(TAG, \"ACC::onAccessibilityEvent: left_button \" + node);\n//                    node.performAction(AccessibilityNodeInfo.ACTION_CLICK);\n//                }\n//\n//                list = nodeInfo\n//                        .findAccessibilityNodeInfosByViewId(\"android:id/button1\");\n//                for (AccessibilityNodeInfo node : list) {\n//                    Log.i(TAG, \"ACC::onAccessibilityEvent: button1 \" + node);\n//                    node.performAction(AccessibilityNodeInfo.ACTION_CLICK);\n//                }\n//            }\n//\n//        }\n//\n//        @Override\n//        public void onServiceConnected() {\n//            Log.i(TAG, \"ACC::onServiceConnected: \");\n//        }\n//        @Override\n//        public void onInterrupt() {\n//            // TODO Auto-generated method stub\n//        }\n//    };\n\n\n\n    private SensorEventListener gyroListener = new SensorEventListener() {\n        @Override\n        public void onSensorChanged(SensorEvent event) {\n            if (MicInstantMode==HandFree_mode|| MicInstantMode==Announce_Mode){\n                addSensorData(0, event.values[0], event.values[1], event.values[2], event.timestamp);\n            }\n        }\n        @Override\n        public void onAccuracyChanged(Sensor sensor, int accuracy) {\n        }\n    };\n\n    private SensorEventListener linearAccListener = new SensorEventListener() {\n        @Override\n        public void onSensorChanged(SensorEvent event) {\n            if (MicInstantMode==HandFree_mode|| MicInstantMode==Announce_Mode) {\n                addSensorData(1, event.values[0], event.values[1], event.values[2], event.timestamp);\n            }\n        }\n\n        @Override\n        public void onAccuracyChanged(Sensor sensor, int accuracy) {\n\n        }\n    };\n\n    public void addSensorData(int idx, float x, float y, float z, long timestamp) {\n        if (timestamp < lastTime[idx] + 3 * 1e6)\n            return;\n        lastTime[idx] = timestamp;\n        for (int i = 0; i < seqLength - 1; i++)\n            System.arraycopy(input[0][i + 1], 3 * idx, input[0][i], 3 * idx, 3);\n        input[0][seqLength - 1][3 * idx] = x;\n        input[0][seqLength - 1][3 * idx + 1] = y;\n        input[0][seqLength - 1][3 * idx + 2] = z;\n        if (idx == 1) {\n            if (skipNum > 0)\n                skipNum--;\n                // 进行识别\n            else {\n                recognizeFirst();\n                recognizeSecond();\n            }\n        }\n\n    }\n\n    private void recognizeFirst() {\n        int offset = 5;\n        float value = input[0][seqLength - offset][5];\n        if (value < 0.5)\n            return;\n        for (int i = 1; i <= 10; i++)\n            if (value < input[0][seqLength - offset - i][5])\n                return;\n        for (int i = 1; i < offset; i++)\n            if (value < input[0][seqLength - offset + i][5])\n                return;\n        float[][][] firstInput = new float[1][10][6];\n        float[][] firstOutput = new float[1][2];\n        for (int i = -5; i < 5; i++)\n            System.arraycopy(input[0][seqLength - offset + i], 0, firstInput[0][5 + i], 0, 6);\n        firstInterpreter.run(firstInput, firstOutput);\n        if (firstOutput[0][1] < 0.99)\n            return;\n        if (!secondFlag) {\n            secondFlag = true;\n            skipNum = 8;\n        }\n        firstTapTime = lastTime[1];\n    }\n\n    private void recognizeSecond() {\n        if (!secondFlag || skipNum > 0)\n            return;\n        if (lastTime[1] - firstTapTime > 600 * 1e6) {\n            secondFlag = false;\n            Log.e(\"Recognize\", \"!!!-1!!!\");\n            return;\n        }\n        secondInterpreter.run(input, output);\n        if (output[0][1] > output[0][0] && output[0][1] > output[0][2]) {\n            //Toast.makeText(this, \"TapTap\", Toast.LENGTH_SHORT).show();\n            //mtvTest.setText(TestText);\n            MicState=MIC_ON;\n            changeMicState();\n            soundPool.play(1,1, 1, 0, 0, 1);\n            //startTimer();\n            Log.e(\"Recognize\", \"!!!TapTap!!!\");\n        }\n        else\n            return;\n        secondFlag = false;\n        skipNum = 30;\n        for (int i = 0; i < seqLength; i++)\n            for (int j = 0; j < 6; j++)\n                input[0][i][j] = 0;\n        vibrator.vibrate(VibrationEffect.createOneShot(300, VibrationEffect.DEFAULT_AMPLITUDE));\n    }\n\n    @Override\n    protected void onDestroy() {\n        stopTimerThread();\n        if (sensorManager != null) {\n            sensorManager.unregisterListener(gyroListener);\n            sensorManager.unregisterListener(linearAccListener);\n        }\n\n        if (firstInterpreter != null) {\n            firstInterpreter.close();\n            firstInterpreter = null;\n        }\n        firstModel = null;\n\n        if (secondInterpreter != null) {\n            secondInterpreter.close();\n            secondInterpreter = null;\n        }\n        secondModel = null;\n\n        if (vibrator != null)\n            vibrator.cancel();\n        super.onDestroy();\n    }\n\n\n    //权限申请\n    private void requestMicrophonePermission() {\n        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.M) {\n            requestPermissions(\n                    new String[]{android.Manifest.permission.RECORD_AUDIO}, REQUEST_RECORD_AUDIO);\n        }\n    }\n\n    private void requestStoragePermission() {\n        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.M) {\n            requestPermissions(\n                    new String[]{Manifest.permission.READ_EXTERNAL_STORAGE,Manifest.permission.WRITE_EXTERNAL_STORAGE,Manifest.permission.RECORD_AUDIO}, REQUEST_EXTERNAL_STORAGE);\n//            requestPermissions(\n//                    new String[]{Manifest.permission.WRITE_EXTERNAL_STORAGE}, REQUEST_EXTERNAL_STORAGE);\n        }\n    }\n\n    private String assetFilePath(Context context, String assetName) {\n        File file = new File(context.getFilesDir(), assetName);\n        if (file.exists() && file.length() > 0) {\n            return file.getAbsolutePath();\n        }\n\n        try (InputStream is = context.getAssets().open(assetName)) {\n            try (OutputStream os = new FileOutputStream(file)) {\n                byte[] buffer = new byte[4 * 1024];\n                int read;\n                while ((read = is.read(buffer)) != -1) {\n                    os.write(buffer, 0, read);\n                }\n                os.flush();\n            }\n            return file.getAbsolutePath();\n        } catch (IOException e) {\n            Log.e(TAG, assetName + \": \" + e.getLocalizedMessage());\n        }\n        return null;\n    }\n\n    //刷新文件目录，使指定uri文件可见\n    private void refreshFilelist(File file){\n        Intent intent =\n                new Intent(Intent.ACTION_MEDIA_SCANNER_SCAN_FILE);\n        intent.setData(Uri.fromFile(file));\n        sendBroadcast(intent);\n    }\n\n    private void saveFile(String data,String path,String fileName) throws IOException {\n\n\n        File dir=Environment.getExternalStoragePublicDirectory(Environment.DIRECTORY_DOWNLOADS);\n        File fullpath=new File(dir,\"/myEmovo/log\");\n        if (!fullpath.exists()){\n            fullpath.mkdirs();\n        }\n\n        File file = new File(fullpath,fileName);\n        try {\n            if (!file.exists()){\n                file.createNewFile();\n            }\n        }catch (IOException e){\n            e.printStackTrace();\n        }\n\n        FileOutputStream fos = new FileOutputStream( file);\n        BufferedWriter writer = new BufferedWriter(new OutputStreamWriter(fos));\n        writer.write(data);\n        writer.flush();\n        writer.close();\n        MediaScannerConnection.scanFile(this,\n                new String[] { file.toString() }, null,\n                new MediaScannerConnection.OnScanCompletedListener() {\n                    public void onScanCompleted(String path, Uri uri) {\n                        Log.i(\"ExternalStorage\", \"Scanned \" + path + \":\");\n                        Log.i(\"ExternalStorage\", \"-> uri=\" + uri);\n                    }\n                });\n\n    }\n\n\n    private void log(float result){\n        String.valueOf(result);\n    }\n\n    private static final int REQUEST_EXTERNAL_STORAGE = 1;\n\n    private static String[] PERMISSIONS_STORAGE = {\n            \"android.permission.READ_EXTERNAL_STORAGE\", \"android.permission.WRITE_EXTERNAL_STORAGE\" };\n\n\n//    private static void verifyStoragePermissions(Activity activity) {\n//        try {\n//        //检测是否有写的权限\n//        int permission = ActivityCompat.checkSelfPermission(activity,\"android.permission.WRITE_EXTERNAL_STORAGE\");\n//            if (permission != PackageManager.PERMISSION_GRANTED) {\n//            // 没有写的权限，去申请写的权限，会弹出对话框\n//            ActivityCompat.requestPermissions(activity, PERMISSIONS_STORAGE,REQUEST_EXTERNAL_STORAGE);\n//            }\n//        } catch (Exception e) {\n//            e.printStackTrace();\n//            }\n//\n//        }\n\n\n    private void showTranslationResult(String result) {\n        mtvTest.setText(result);\n    }\n    private void changeEmoState(int EmoState){\n        int res;\n        String EmoHint=\"\";\n        if (EmoState==EMO_NEUTRAL) {\n            res = R.drawable.emoji_neutral;\n            EmoHint=\"I am satisfied!\";\n        }\n        else if(EmoState==EMO_ANGER){\n            res=R.drawable.emoji__anger;\n            EmoHint=\"I am angry!\";\n        }\n        else {\n            res=R.drawable.emoji__anger;\n            EmoHint=\"I am satisfied!\";\n        }\n        mImgvEmoState.setImageResource(res);\n        mtvEmoState.setText(EmoHint);\n\n    }\n\n\n\n    private void realtimeRecorder(){\n        android.os.Process.setThreadPriority(android.os.Process.THREAD_PRIORITY_AUDIO);\n\n        int bufferSize = AudioRecord.getMinBufferSize(SAMPLE_RATE, AudioFormat.CHANNEL_IN_MONO, AudioFormat.ENCODING_PCM_FLOAT);\n        AudioRecord record = new AudioRecord(MediaRecorder.AudioSource.DEFAULT, SAMPLE_RATE, AudioFormat.CHANNEL_IN_MONO, AudioFormat.ENCODING_PCM_FLOAT,\n                bufferSize);\n\n        if (record.getState() != AudioRecord.STATE_INITIALIZED) {\n            Log.e(LOG_TAG, \"Audio Record can't initialize!\");\n            throw new IllegalStateException();\n            //return;\n        }\n        record.startRecording();\n\n        long shortsRead = 0;\n        int recordingOffset = 0;\n        float[] audioBuffer = new float[bufferSize / 2];\n        float[] recordingBuffer = new float[RECORDING_LENGTH];\n\n        while (shortsRead < RECORDING_LENGTH/audioBuffer.length*audioBuffer.length) {\n            int numberOfShort = record.read(audioBuffer, 0, audioBuffer.length,AudioRecord.READ_NON_BLOCKING);\n            shortsRead += numberOfShort;\n            System.arraycopy(audioBuffer, 0, recordingBuffer, recordingOffset, numberOfShort);\n            recordingOffset += numberOfShort;\n        }\n\n        record.stop();\n        record.release();\n        stopTimerThread();\n\n        runOnUiThread(new Runnable() {\n            @Override\n            public void run() {\n                mtvTest.setText(\"Recognizing...\");\n            }\n        });\n\n//        int min = (int) Collections.min(Arrays.asList(recordingBuffer));\n//        int max = (int) Collections.max(Arrays.asList(recordingBuffer));\n//        System.out.println(\"最小值: \" + min);\n//        System.out.println(\"最大值: \" + max);\n\n        //send data to chaquo preprocess module\n        Python py=Python.getInstance();\n        PyObject data=py.getModule(\"DataPre\").callAttr(\"Preprocess\",recordingBuffer);\n        float[] inputfloat =data.toJava(float[].class);\n        //recognize\n        final String result = recognize(inputfloat,(int)562);\n\n        try {\n            saveFile(result,\"/logs\",\"log.txt\");\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n\n        runOnUiThread(new Runnable() {\n            @Override\n            public void run() {\n                SetProgress(mprobarEmoInference,mprobarEmoInference.getProgress(), (int) (EmoInference*100));\n                showTranslationResult(result);\n                changeEmoState(EmoState);\n                mButton.setEnabled(true);\n                mtvTest.setText(\"Recording\");\n\n            }\n        });\n\n    }\n\n    private void initVoicePrint(){\n        Thread initVPthread=new Thread(new Runnable() {\n            @Override\n            public void run() {\n                voicePrint.vpCreateGroup();\n            }\n        });\n        initVPthread.start();\n\n    }\n\n    private Runnable VoicePrint_runnable =new Runnable() {\n        @Override\n        public void run() {\n            try {\n                Log.i(TAG,\"VoicePrint_runnable: start..\");\n                toFileRecorder_byAR();\n                if (VoicePrintFlag==VoicePrint_CREATEFEATURE){\n                    voicePrint.vpCreateFeature();\n                }\n                else if(VoicePrintFlag==VoicePrint_CHECKFEATURE){\n                    voicePrint.vpSearchOneFeature();\n                }\n                else {\n                    Log.i(TAG,\"Warning:in VoicePrint_runnable empty VoicePrintFlag!\");\n                }\n\n\n            } catch (FileNotFoundException e) {\n                e.printStackTrace();\n            }\n        }\n    };\n\n    private void startVoicePrint(int VoicePrintFlag){\n        this.VoicePrintFlag=VoicePrintFlag;\n        VoicePrint_thread=new Thread(VoicePrint_runnable);\n        VoicePrint_thread.start();\n    }\n\n    private void toFileRecorder_byAR() throws FileNotFoundException {\n        android.os.Process.setThreadPriority(android.os.Process.THREAD_PRIORITY_AUDIO);\n\n        int bufferSize = AudioRecord.getMinBufferSize(SAMPLE_RATE, AudioFormat.CHANNEL_IN_MONO, AudioFormat.ENCODING_PCM_16BIT);\n        AudioRecord record = new AudioRecord(MediaRecorder.AudioSource.DEFAULT, SAMPLE_RATE, AudioFormat.CHANNEL_IN_MONO, AudioFormat.ENCODING_PCM_16BIT,\n                bufferSize);\n\n        if (record.getState() != AudioRecord.STATE_INITIALIZED) {\n            Log.e(LOG_TAG, \"Audio Record can't initialize!\");\n            throw new IllegalStateException();\n            //return;\n        }\n        record.startRecording();\n\n        long shortsRead = 0;\n        int recordingOffset = 0;\n        short[] audioBuffer = new short[bufferSize / 2];\n        short[] recordingBuffer = new short[RECORDING_LENGTH];\n\n        while (shortsRead < RECORDING_LENGTH/audioBuffer.length*audioBuffer.length) {\n            int numberOfShort = record.read(audioBuffer, 0, audioBuffer.length,AudioRecord.READ_NON_BLOCKING);\n            shortsRead += numberOfShort;\n            System.arraycopy(audioBuffer, 0, recordingBuffer, recordingOffset, numberOfShort);\n            recordingOffset += numberOfShort;\n        }\n\n        record.stop();\n        record.release();\n        //stopTimerThread();\n\n        Wave wavFile= new Wave(SAMPLE_RATE, (short) 1,recordingBuffer,0,recordingBuffer.length-1);\n        File fullpath=new File(Environment.getExternalStoragePublicDirectory(Environment.DIRECTORY_DOWNLOADS),\n                \"/myEmovo/record\");\n        if (!fullpath.exists()){\n            fullpath.mkdirs();\n        }\n        File dir=new File(fullpath,\"record.wav\");\n        //System.out.println(dir);\n        //File dir=new File(\"/data/data/org.pytorch.demo.speechrecognition/files/chaquopy/AssetFinder/app\",\"record.wav\");\n        if (!dir.exists()){\n            System.out.println(\"warning:dir not exits!\");\n        }\n        wavFile.wroteToFile(dir);\n        FileInputStream ios=new FileInputStream(dir);\n\n//        int min = (int) Collections.min(Arrays.asList(recordingBuffer));\n//        int max = (int) Collections.max(Arrays.asList(recordingBuffer));\n//        System.out.println(\"最小值: \" + min);\n//        System.out.println(\"最大值: \" + max);\n\n//        Python py=Python.getInstance();\n//        PyObject data=py.getModule(\"DataPre\").callAttr(\"Preprocess2\",ios);\n//        float[] inputfloat =data.toJava(float[].class);\n//\n//        final String result = recognize(inputfloat,(int)562);\n//        //save(result,\"log.txt\");\n//        try {\n//            saveFile(result,\"/logs\",\"log.txt\");\n//        } catch (IOException e) {\n//            e.printStackTrace();\n//        }\n//\n//        runOnUiThread(new Runnable() {\n//            @Override\n//            public void run() {\n//                showTranslationResult(result);\n//                mButton.setEnabled(true);\n//                //mTextView.setText(\"Start\");\n//            }\n//        });\n\n    }\n\n    //\n    private class MyTimerTask extends TimerTask {\n        private MediaRecorder recorder=null;\n        private File filedir=null;\n        MyTimerTask(MediaRecorder recorder,File filedir){\n            this.recorder=recorder;\n            this.filedir=filedir;\n        }\n        public void run() {\n            recorder.stop();\n            recorder.release();\n\n            Python py=Python.getInstance();\n            PyObject data=py.getModule(\"DataPre\").callAttr(\"Preprocess2\",filedir);\n            float[] inputfloat =data.toJava(float[].class);\n\n\n            final String result = recognize(inputfloat,(int)562);\n            //save(result,\"log.txt\");\n            try {\n                saveFile(result,\"/logs\",\"log.txt\");\n            } catch (IOException e) {\n                e.printStackTrace();\n            }\n\n            runOnUiThread(new Runnable() {\n                @Override\n                public void run() {\n                    showTranslationResult(result);\n                    mButton.setEnabled(true);\n                    mtvTest.setText(\"Start\");\n                }\n            });\n\n\n\n        }\n    }\n    //先将录音存为音频，再用librosa直接读取\n    private void toFileRecorder_byMR(){\n        android.os.Process.setThreadPriority(android.os.Process.THREAD_PRIORITY_AUDIO);\n        final MediaRecorder recorder = new MediaRecorder();\n        //ContentValues values = new ContentValues(3);\n        //values.put(MediaStore.MediaColumns.TITLE, fileName);\n        recorder.setAudioSource(MediaRecorder.AudioSource.MIC);\n        recorder.setOutputFormat(MediaRecorder.OutputFormat.MPEG_4);\n        recorder.setAudioEncoder(MediaRecorder.AudioEncoder.AAC);\n        //recorder.setMaxDuration(AUDIO_LEN_IN_SECOND);\n        File fullpath=new File(Environment.getExternalStoragePublicDirectory(Environment.DIRECTORY_DOWNLOADS),\n                \"/myEmovo/record\");\n        if (!fullpath.exists()){\n            fullpath.mkdirs();\n        }\n\n        File dir=new File(fullpath,\"record.m4a\");\n        recorder.setOutputFile(dir);\n        try {\n            recorder.prepare();\n        } catch (Exception e){\n            e.printStackTrace();\n            while (true){\n                System.out.println(\"prepare wrong!\");\n            }\n\n        }\n        recorder.start();\n\n        Timer timer = new Timer();\n        timer.schedule(new MyTimerTask(recorder,dir), 2000, 5000);\n    }\n\n    public void run() {\n        Log.i(TAG,\"recorder running...\");\n        //toFileRecorder_byMR();\n        //realtimeRecorder();\n//        try {\n//            toFileRecorder_byAR();\n//        } catch (FileNotFoundException e) {\n//            e.printStackTrace();\n//        }\n\n    }\n\n    private String recognize(float[] floatInputBuffer,int shape0) {\n        if (mModuleEncoder == null) {\n\n            mModuleEncoder = LiteModuleLoader.load(assetFilePath(getApplicationContext(), \"Model2.ptl\"));\n        }\n        int Length=floatInputBuffer.length;\n        double wav2vecinput[] = new double[Length];\n        for (int n = 0; n < Length; n++)\n            wav2vecinput[n] = floatInputBuffer[n];\n\n        FloatBuffer inTensorBuffer = Tensor.allocateFloatBuffer(Length);\n        for (double val : wav2vecinput)\n            inTensorBuffer.put((float)val);\n\n        Tensor inTensor = Tensor.fromBlob(inTensorBuffer, new long[]{(int)Length/shape0,(int)Length/shape0, shape0});\n        Tensor ResultTensor=mModuleEncoder.forward(IValue.from(inTensor)).toTensor();\n        float[] ResultFloat=ResultTensor.getDataAsFloatArray();\n        float result =ResultFloat[0]/(ResultFloat[0]+ResultFloat[1]);\n        this.EmoInference=result;\n        if (result<0.5){\n            this.EmoState=EMO_NEUTRAL;\n        }\n        else if (result>0.5){\n            this.EmoState=EMO_ANGER;\n        }\n\n\n        return String.valueOf(result);\n    }\n\n    public void SetProgress(final ProgressBar view, int startprogress, int endprogress) {//进度条的控件，以及起始的值\n\n        view.setVisibility(View.VISIBLE);\n\n\n        ValueAnimator animator = ValueAnimator.ofInt(startprogress, endprogress).setDuration(800);\n\n        animator.addUpdateListener(new ValueAnimator.AnimatorUpdateListener() {\n            @Override\n            public void onAnimationUpdate(ValueAnimator valueAnimator) {\n                view.setProgress((int) valueAnimator.getAnimatedValue());\n            }\n        });\n        animator.start();\n    }\n\n\n\n}
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/app/src/main/java/org/pytorch/demo/speechrecognition/MainActivity.java b/app/src/main/java/org/pytorch/demo/speechrecognition/MainActivity.java
--- a/app/src/main/java/org/pytorch/demo/speechrecognition/MainActivity.java	(revision 03385cca6ee93d9b615038af3e6771620fdf2887)
+++ b/app/src/main/java/org/pytorch/demo/speechrecognition/MainActivity.java	(date 1654314806383)
@@ -51,6 +51,7 @@
 import android.widget.TextView;
 import android.widget.Toast;
 
+import androidx.annotation.NonNull;
 import androidx.appcompat.app.AppCompatActivity;
 import androidx.core.app.ActivityCompat;
 import androidx.core.content.ContextCompat;
@@ -530,7 +531,6 @@
     private void changeMicState(){
         int res;
         String MicHint="";
-        startTimer();
 
         if (MicState==MIC_ON) {
             res = R.drawable.mic_on;
@@ -538,6 +538,7 @@
                 TmAccessibilityService.mService.ClickView(TmAccessibilityService.mService.vid_InMeeting_Mic);
             }
             TmAccessibilityService.mService.SetMicMute(false);
+            startTimer();
             MicHint="Microphone ON!";
         }
         else if(EmoState==MIC_OFF){
@@ -630,9 +631,10 @@
             TimerHandler.postDelayed(TimerRunnable, 1000);
             Timer_time+=1;
             Log.e(TAG, "Timer running");
-            if(Timer_time>5){
+            if(Timer_time>3){
                 stopTimer();
                 Log.i(TAG,"Timer:"+Timer_time);
+                // stop recording and begin testing
                 //speechRecognizer.stopListening();
             }
         }
@@ -660,7 +662,7 @@
         Log.e(TAG, "startTimer");
     }
 
-    private void initAccessibility(Context ct, String serviceClass){
+    private void initAccessibility(@NonNull Context ct, String serviceClass){
         boolean haspermisssion=false;
         int ok = 0;
         try {
Index: .idea/runConfigurations.xml
===================================================================
diff --git a/.idea/runConfigurations.xml b/.idea/runConfigurations.xml
deleted file mode 100644
--- a/.idea/runConfigurations.xml	(revision 03385cca6ee93d9b615038af3e6771620fdf2887)
+++ /dev/null	(revision 03385cca6ee93d9b615038af3e6771620fdf2887)
@@ -1,12 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<project version="4">
-  <component name="RunConfigurationProducerService">
-    <option name="ignoredProducers">
-      <set>
-        <option value="org.jetbrains.plugins.gradle.execution.test.runner.AllInPackageGradleConfigurationProducer" />
-        <option value="org.jetbrains.plugins.gradle.execution.test.runner.TestClassGradleConfigurationProducer" />
-        <option value="org.jetbrains.plugins.gradle.execution.test.runner.TestMethodGradleConfigurationProducer" />
-      </set>
-    </option>
-  </component>
-</project>
\ No newline at end of file
Index: .idea/gradle.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project version=\"4\">\n  <component name=\"GradleMigrationSettings\" migrationVersion=\"1\" />\n  <component name=\"GradleSettings\">\n    <option name=\"linkedExternalProjectsSettings\">\n      <GradleProjectSettings>\n        <option name=\"testRunner\" value=\"PLATFORM\" />\n        <option name=\"distributionType\" value=\"DEFAULT_WRAPPED\" />\n        <option name=\"externalProjectPath\" value=\"$PROJECT_DIR$\" />\n        <option name=\"gradleJvm\" value=\"1.8\" />\n        <option name=\"modules\">\n          <set>\n            <option value=\"$PROJECT_DIR$\" />\n            <option value=\"$PROJECT_DIR$/app\" />\n          </set>\n        </option>\n        <option name=\"resolveModulePerSourceSet\" value=\"false\" />\n      </GradleProjectSettings>\n    </option>\n  </component>\n</project>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/gradle.xml b/.idea/gradle.xml
--- a/.idea/gradle.xml	(revision 03385cca6ee93d9b615038af3e6771620fdf2887)
+++ b/.idea/gradle.xml	(date 1654180882292)
@@ -4,7 +4,7 @@
   <component name="GradleSettings">
     <option name="linkedExternalProjectsSettings">
       <GradleProjectSettings>
-        <option name="testRunner" value="PLATFORM" />
+        <option name="testRunner" value="GRADLE" />
         <option name="distributionType" value="DEFAULT_WRAPPED" />
         <option name="externalProjectPath" value="$PROJECT_DIR$" />
         <option name="gradleJvm" value="1.8" />
Index: .idea/compiler.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/compiler.xml b/.idea/compiler.xml
new file mode 100644
--- /dev/null	(date 1654180951483)
+++ b/.idea/compiler.xml	(date 1654180951483)
@@ -0,0 +1,6 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<project version="4">
+  <component name="CompilerConfiguration">
+    <bytecodeTargetLevel target="1.8" />
+  </component>
+</project>
\ No newline at end of file
Index: .idea/vcs.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/vcs.xml b/.idea/vcs.xml
new file mode 100644
--- /dev/null	(date 1654180882290)
+++ b/.idea/vcs.xml	(date 1654180882290)
@@ -0,0 +1,6 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<project version="4">
+  <component name="VcsDirectoryMappings">
+    <mapping directory="" vcs="Git" />
+  </component>
+</project>
\ No newline at end of file
Index: .idea/misc.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project version=\"4\">\n  <component name=\"ProjectRootManager\" version=\"2\" languageLevel=\"JDK_1_8\" project-jdk-name=\"1.8\" project-jdk-type=\"JavaSDK\">\n    <output url=\"file://$PROJECT_DIR$/build/classes\" />\n  </component>\n  <component name=\"ProjectType\">\n    <option name=\"id\" value=\"Android\" />\n  </component>\n</project>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/misc.xml b/.idea/misc.xml
--- a/.idea/misc.xml	(revision 03385cca6ee93d9b615038af3e6771620fdf2887)
+++ b/.idea/misc.xml	(date 1654180951479)
@@ -1,6 +1,6 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <project version="4">
-  <component name="ProjectRootManager" version="2" languageLevel="JDK_1_8" project-jdk-name="1.8" project-jdk-type="JavaSDK">
+  <component name="ProjectRootManager" version="2" languageLevel="JDK_1_8" default="true" project-jdk-name="1.8" project-jdk-type="JavaSDK">
     <output url="file://$PROJECT_DIR$/build/classes" />
   </component>
   <component name="ProjectType">
